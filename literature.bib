@inproceedings{abend2009,
  title = {Unsupervised {{Argument Identification}} for {{Semantic Role Labeling}}},
  booktitle = {Proceedings of the {{Joint Conference}} of the 47th {{Annual Meeting}} of the {{ACL}} and the 4th {{International Joint Conference}} on {{Natural Language Processing}} of the {{AFNLP}}},
  author = {Abend, Omri and Reichart, Roi and Rappoport, Ari},
  date = {2009-08},
  pages = {28--36},
  publisher = {{Association for Computational Linguistics}},
  location = {{Suntec, Singapore}},
  eventtitle = {{{ACL-IJCNLP}} 2009},
  file = {/Users/siyu/Zotero/storage/AYP5AWF4/Abend et al. - 2009 - Unsupervised Argument Identification for Semantic .pdf}
}

@book{agel2003,
  title = {Dependenz Und {{Valenz}}: {{Ein}} Internationales {{Handbuch}} Zeitgenössischer {{Forschung}}},
  shorttitle = {Dependenz Und {{Valenz}}},
  editor = {Ágel, Vilmos and Eichinger, Ludwig M. and Eroms, Hans-Werner and Hellwig, Peter and Heringer, Hans Jürgen and Lobin, Henning},
  date = {2003-11-05},
  publisher = {{Walter de Gruyter}},
  doi = {10.1515/9783110141900.1},
  url = {https://www.degruyter.com/document/doi/10.1515/9783110141900.1/html},
  urldate = {2022-11-14},
  isbn = {978-3-11-014190-0},
  file = {/Users/siyu/Zotero/storage/CIMGR9Y5/Ágel et al. - 2003 - Dependenz und Valenz Ein internationales Handbuch.pdf}
}

@book{agel2006,
  title = {Dependenz Und {{Valenz}}: {{Ein}} Internationales {{Handbuch}} Der Zeitgenössischen {{Forschung}}},
  shorttitle = {Dependenz Und {{Valenz}}},
  editor = {Ágel, Vilmos and Eichinger, Ludwig M. and Eroms, Hans-Werner and Hellwig, Peter and Heringer, Hans Jürgen and Lobin, Henning},
  date = {2006-07-18},
  publisher = {{De Gruyter}},
  doi = {10.1515/9783110171525.2},
  url = {https://www.degruyter.com/document/doi/10.1515/9783110171525.2/html},
  urldate = {2022-11-14},
  editora = {Rau, Guta},
  editoratype = {collaborator},
  isbn = {978-3-11-019984-0},
  file = {/Users/siyu/Zotero/storage/HAYEGAAK/Ágel et al. - 2006 - Dependenz und Valenz Ein internationales Handbuch.pdf}
}

@book{allerton1982,
  title = {Valency and the {{English}} Verb},
  author = {Allerton, D. J.},
  date = {1982},
  publisher = {{Academic Press}},
  location = {{London ; New York}},
  isbn = {978-0-12-052980-3},
  pagetotal = {168},
  keywords = {Dependency grammar,English language,Verb},
  file = {/Users/siyu/Zotero/storage/3WEKHBKT/D. J. (Author) Allerton - Valency and the English verb (1982, Academic Press Inc) - libgen.li.pdf}
}

@article{antoniak2018,
  title = {Evaluating the {{Stability}} of {{Embedding-based Word Similarities}}},
  author = {Antoniak, Maria and Mimno, David},
  date = {2018},
  journaltitle = {Transactions of the Association for Computational Linguistics},
  volume = {6},
  pages = {107--119},
  publisher = {{MIT Press}},
  location = {{Cambridge, MA}},
  doi = {10.1162/tacl_a_00008},
  url = {https://aclanthology.org/Q18-1008},
  urldate = {2022-05-06},
  abstract = {Word embeddings are increasingly being used as a tool to study word associations in specific corpora. However, it is unclear whether such embeddings reflect enduring properties of language or if they are sensitive to inconsequential variations in the source documents. We find that nearest-neighbor distances are highly sensitive to small changes in the training corpus for a variety of algorithms. For all methods, including specific documents in the training set can result in substantial variations. We show that these effects are more prominent for smaller training corpora. We recommend that users never rely on single embedding models for distance calculations, but rather average over multiple bootstrap samples, especially for small corpora.},
  file = {/Users/siyu/Zotero/storage/8LUGJUJU/Antoniak and Mimno - 2018 - Evaluating the Stability of Embedding-based Word S.pdf}
}

@incollection{baker1997,
  title = {Thematic {{Roles}} and {{Syntactic Structure}}},
  booktitle = {Elements of {{Grammar}}: {{Handbook}} in {{Generative Syntax}}},
  author = {Baker, Mark C.},
  editor = {Haegeman, Liliane},
  date = {1997},
  series = {Kluwer {{International Handbooks}} of {{Linguistics}}},
  pages = {73--137},
  publisher = {{Springer Netherlands}},
  location = {{Dordrecht}},
  doi = {10.1007/978-94-011-5420-8_2},
  url = {https://doi.org/10.1007/978-94-011-5420-8_2},
  urldate = {2022-06-20},
  abstract = {One central task for any theory of grammar is to solve the so-called “linking problem”: the problem of discovering regularities in how the participants of an event are expressed in surface grammatical forms and explaining those regularities.},
  isbn = {978-94-011-5420-8},
  langid = {english},
  keywords = {Dative Alternation,Dative Shift,Direct Object,Locative Alternation,Syntactic Structure},
  file = {/Users/siyu/Zotero/storage/T6XBUK4M/Baker - 1997 - Thematic Roles and Syntactic Structure.pdf}
}

@inproceedings{baker2020,
  title = {Exploring {{Crosslinguistic Frame Alignment}}},
  booktitle = {Proceedings of the {{International FrameNet Workshop}} 2020: {{Towards}} a {{Global}}, {{Multilingual FrameNet}}},
  author = {Baker, Collin F. and Lorenzi, Arthur},
  date = {2020-05},
  pages = {77--84},
  publisher = {{European Language Resources Association}},
  location = {{Marseille, France}},
  url = {https://aclanthology.org/2020.framenet-1.11},
  urldate = {2022-09-25},
  abstract = {The FrameNet (FN) project at the International Computer Science Institute in Berkeley (ICSI), which documents the core vocabulary of contemporary English, was the first lexical resource based on Fillmore's theory of Frame Semantics. Berkeley FrameNet has inspired related projects in roughly a dozen other languages, which have evolved somewhat independently; the current Multilingual FrameNet project (MLFN) is an attempt to find alignments between all of them. The alignment problem is complicated by the fact that these projects have adhered to the Berkeley FrameNet model to varying degrees, and they were also founded at different times, when different versions of the Berkeley FrameNet data were available. We describe several new methods for finding relations of similarity between semantic frames across languages. We will demonstrate ViToXF, a new tool which provides interactive visualizations of these cross-lingual relations, between frames, lexical units, and frame elements, based on resources such as multilingual dictionaries and on shared distributional vector spaces, making clear the strengths and weaknesses of different alignment methods.},
  isbn = {979-10-95546-58-0},
  langid = {english},
  file = {/Users/siyu/Zotero/storage/9AZ32X3V/Baker and Lorenzi - 2020 - Exploring Crosslinguistic Frame Alignment.pdf}
}

@article{bencini2000,
  title = {The {{Contribution}} of {{Argument Structure Constructions}} to {{Sentence Meaning}}},
  author = {Bencini, Giulia M. L and Goldberg, Adele E},
  date = {2000-11-01},
  journaltitle = {Journal of Memory and Language},
  shortjournal = {Journal of Memory and Language},
  volume = {43},
  number = {4},
  pages = {640--651},
  issn = {0749-596X},
  doi = {10.1006/jmla.2000.2757},
  url = {https://www.sciencedirect.com/science/article/pii/S0749596X00927578},
  urldate = {2022-06-20},
  abstract = {What types of linguistic information do people use to construct the meaning of a sentence? Most linguistic theories and psycholinguistic models of sentence comprehension assume that the main determinant of sentence meaning is the verb. This idea was argued explicitly in Healy and Miller (1970). When asked to sort sentences according to their meaning, Healy and Miller found that participants were more likely to sort sentences according to the main verb in the sentence than according to the subject argument. On the basis of these results, the authors concluded that the verb was the main determinant of sentence meaning. In this study we used the same sorting paradigm to explore the possibility that there is another strong influence on sentence interpretation: the configuration of complements (the argument structure construction). Our results showed that participants did produce sorts by construction, despite a well-documented tendency for subjects to sort on the basis of a single dimension, which would favor sorts by verb.},
  langid = {english},
  keywords = {argument structure constructions,sentence meaning,verbs},
  file = {/Users/siyu/Zotero/storage/3ZCJQT48/Bencini and Goldberg - 2000 - The Contribution of Argument Structure Constructio.pdf;/Users/siyu/Zotero/storage/QF5S9RUJ/S0749596X00927578.html}
}

@article{bickel2014,
  title = {Semantic Role Clustering: {{An}} Empirical Assessment of Semantic Role Types in Non-Default Case Assignment},
  shorttitle = {Semantic Role Clustering},
  author = {Bickel, Balthasar and Zakharko, Taras and Bierkandt, Lennart and Witzlack-Makarevich, Alena},
  date = {2014-01-01},
  journaltitle = {Studies in Language},
  volume = {38},
  number = {3},
  pages = {485--511},
  publisher = {{John Benjamins}},
  issn = {0378-4177, 1569-9978},
  doi = {10.1075/sl.38.3.03bic},
  url = {https://www.jbe-platform.com/content/journals/10.1075/sl.38.3.03bic},
  urldate = {2022-09-25},
  abstract = {This paper seeks to determine to what extent there is cross-linguistic evidence for postulating clusters of predicate-specific semantic roles such as experiencer, cognizer, possessor, etc. For this, we survey non-default case assignments in a sample of 141 languages and annotate the associated predicates for cross-linguistically recurrent semantic roles, such as ‘the one who feels cold’, ‘the one who eats sth.’, ‘the thing that is being eaten’. We then determine to what extent these roles are treated alike across languages, i.e. repeatedly grouped together under the same non-default case marker or under the same specific alternation with a non-default marker. Applying fuzzy cluster and NeighborNet algorithms to these data reveals cross-linguistic evidence for role clusters around experiencers, undergoers of body processes, and cognizers/perceivers in one- and two-place predicates; and around sources and transmitted speech in three-place predicates. No support emerges from non-default case assignment for any other role clusters that are traditionally assumed (e.g. for any distinctions among objects of two-argument predicates, or for distinctions between themes and instruments).},
  langid = {english},
  file = {/Users/siyu/Zotero/storage/KSSAX8ER/Bickel et al. - 2014 - Semantic role clustering An empirical assessment .pdf;/Users/siyu/Zotero/storage/HSLGIE8W/sl.38.3.html}
}

@incollection{bickel2015,
  ids = {heine2015a},
  title = {Distributional {{Typology}}},
  booktitle = {The {{Oxford Handbook}} of {{Linguistic Analysis}}},
  author = {Bickel, Balthasar},
  editor = {Heine, Bernd and Narrog, Heiko},
  date = {2015-01-01},
  publisher = {{Oxford University Press}},
  doi = {10.1093/oxfordhb/9780199677078.013.0046},
  url = {http://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780199677078.001.0001/oxfordhb-9780199677078-e-46},
  urldate = {2021-01-25},
  abstract = {Over the past two decades, linguistic typology has been moving increasingly away from its original goal of classifying languages into ideal types that would be constrained by categorical universals. What has been emerging as a new paradigm instead starts from the distribution of structures in the world, asking “what’s where why?” I present here a concrete approach to this question, called ‘Distributional Typology’. The approach starts from causal theories on the forces that affect language change, from processing preferences to the historical contingencies of language contact. The predictions of these theories can then be tested against fine-grained matrices of cross-linguistic diversity, using statistical methods for estimating diachronic trends from synchronic distributions.},
  isbn = {978-0-19-967707-8},
  langid = {english},
  file = {/Users/siyu/Zotero/storage/P4DRXNKH/Heine et al. - 2015 - Distributional Typology.pdf}
}

@inbook{blasi2015,
  title = {Assessing Transitivity Prominence from a Statistical Perspective: {{A}} Commentary on {{Martin Haspelmath}}’s “{{Transitivity}} Prominence”},
  booktitle = {Valency Classes in the {{World}}'s Languages: {{Volume}} 1 {{Introducing}} the Framework, and Case Studies from {{Africa}} and {{Eurasia}}},
  author = {Blasi, Damián},
  date = {2015},
  volume = {1},
  pages = {149--154},
  publisher = {{De Gruyter Mouton}},
  location = {{Berlin; Boston}},
  bookauthor = {Malchukov, Andrej and Comrie, Bernard},
  isbn = {978-3-11-033294-0},
  langid = {english},
  volumes = {2},
  annotation = {OCLC: 1015602777}
}

@article{boleda2020,
  title = {Distributional {{Semantics}} and {{Linguistic Theory}}},
  author = {Boleda, Gemma},
  date = {2020},
  journaltitle = {Annual Review of Linguistics},
  volume = {6},
  number = {1},
  pages = {213--234},
  doi = {10.1146/annurev-linguistics-011619-030303},
  url = {https://doi.org/10.1146/annurev-linguistics-011619-030303},
  urldate = {2022-05-11},
  abstract = {Distributional semantics provides multidimensional, graded, empirically induced word representations that successfully capture many aspects of meaning in natural languages, as shown by a large body of research in computational linguistics; yet, its impact in theoretical linguistics has so far been limited. This review provides a critical discussion of the literature on distributional semantics, with an emphasis on methods and results that are relevant for theoretical linguistics, in three areas: semantic change, polysemy and composition, and the grammar–semantics interface (specifically, the interface of semantics with syntax and with derivational morphology). The goal of this review is to foster greater cross-fertilization of theoretical and computational approaches to language as a means to advance our collective knowledge of how it works.},
  keywords = {composition,computational semantics,derivational morphology,diachronic semantics,distributional semantics,polysemy,semantic change,semantic spaces,syntax–semantics interface,vector space models,vector spaces},
  annotation = {\_eprint: https://doi.org/10.1146/annurev-linguistics-011619-030303},
  file = {/Users/siyu/Zotero/storage/4BXMVM48/Boleda - 2020 - Distributional Semantics and Linguistic Theory.pdf}
}

@inproceedings{bowern2019,
  title = {Semantic {{Change}} and {{Semantic Stability}}: {{Variation}} Is {{Key}}},
  shorttitle = {Semantic {{Change}} and {{Semantic Stability}}},
  booktitle = {Proceedings of the 1st {{International Workshop}} on {{Computational Approaches}} to {{Historical Language Change}}},
  author = {Bowern, Claire},
  date = {2019-08},
  pages = {48--55},
  publisher = {{Association for Computational Linguistics}},
  location = {{Florence, Italy}},
  doi = {10.18653/v1/W19-4706},
  url = {https://aclanthology.org/W19-4706},
  urldate = {2022-05-11},
  abstract = {I survey some recent approaches to studying change in the lexicon, particularly change in meaning across phylogenies. I briefly sketch an evolutionary approach to language change and point out some issues in recent approaches to studying semantic change that rely on temporally stratified word embeddings. I draw illustrations from lexical cognate models in Pama-Nyungan to identify meaning classes most appropriate for lexical phylogenetic inference, particularly highlighting the importance of variation in studying change over time.},
  file = {/Users/siyu/Zotero/storage/JDFH329Q/Bowern - 2019 - Semantic Change and Semantic Stability Variation .pdf}
}

@inproceedings{burdick2021,
  title = {Analyzing the {{Surprising Variability}} in {{Word Embedding Stability Across Languages}}},
  booktitle = {Proceedings of the 2021 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Burdick, Laura and Kummerfeld, Jonathan K. and Mihalcea, Rada},
  date = {2021-11},
  pages = {5891--5901},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online and Punta Cana, Dominican Republic}},
  url = {https://aclanthology.org/2021.emnlp-main.476},
  urldate = {2021-11-10},
  abstract = {Word embeddings are powerful representations that form the foundation of many natural language processing architectures, both in English and in other languages. To gain further insight into word embeddings, we explore their stability (e.g., overlap between the nearest neighbors of a word in different embedding spaces) in diverse languages. We discuss linguistic properties that are related to stability, drawing out insights about correlations with affixing, language gender systems, and other features. This has implications for embedding use, particularly in research that uses them to study language trends.},
  eventtitle = {{{EMNLP}} 2021},
  file = {/Users/siyu/Zotero/storage/3I7NYHDM/Burdick et al. - 2021 - Analyzing the Surprising Variability in Word Embed.pdf}
}

@article{cotterell2019,
  title = {On the {{Complexity}} and {{Typology}} of {{Inflectional Morphological Systems}}},
  author = {Cotterell, Ryan and Kirov, Christo and Hulden, Mans and Eisner, Jason},
  date = {2019},
  journaltitle = {Transactions of the Association for Computational Linguistics},
  volume = {7},
  pages = {327--342},
  publisher = {{MIT Press}},
  location = {{Cambridge, MA}},
  doi = {10.1162/tacl_a_00271},
  url = {https://aclanthology.org/Q19-1021},
  urldate = {2022-06-20},
  abstract = {We quantify the linguistic complexity of different languages' morphological systems. We verify that there is a statistically significant empirical trade-off between paradigm size and irregularity: A language's inflectional paradigms may be either large in size or highly irregular, but never both. We define a new measure of paradigm irregularity based on the conditional entropy of the surface realization of a paradigm— how hard it is to jointly predict all the word forms in a paradigm from the lemma. We estimate irregularity by training a predictive model. Our measurements are taken on large morphological paradigms from 36 typologically diverse languages.},
  file = {/Users/siyu/Zotero/storage/S9CFFY5E/Cotterell et al. - 2019 - On the Complexity and Typology of Inflectional Mor.pdf}
}

@article{coupe2019,
  title = {Different Languages, Similar Encoding Efficiency: {{Comparable}} Information Rates across the Human Communicative Niche},
  shorttitle = {Different Languages, Similar Encoding Efficiency},
  author = {Coupé, Christophe and Oh, Yoon Mi and Dediu, Dan and Pellegrino, François},
  date = {2019-09-04},
  journaltitle = {Science Advances},
  volume = {5},
  number = {9},
  pages = {eaaw2594},
  publisher = {{American Association for the Advancement of Science}},
  doi = {10.1126/sciadv.aaw2594},
  url = {https://www.science.org/doi/10.1126/sciadv.aaw2594},
  urldate = {2022-07-12},
  file = {/Users/siyu/Zotero/storage/Q7MGHZ7I/Coupé et al. - 2019 - Different languages, similar encoding efficiency .pdf}
}

@book{croft2012,
  title = {Verbs: Aspect and Causal Structure},
  shorttitle = {Verbs},
  author = {Croft, William},
  date = {2012},
  publisher = {{Oxford University Press}},
  location = {{Oxford}},
  isbn = {978-0-19-924859-9},
  langid = {english},
  annotation = {OCLC: 922668572},
  file = {/Users/siyu/Zotero/storage/LAF597NF/Croft - 2013 - Verbs aspect and causal structure.pdf}
}

@inproceedings{croft2017,
  title = {Linguistic {{Typology}} Meets {{Universal Dependencies}}},
  booktitle = {Proceedings of the 15th {{International Workshop}} on {{Treebanks}} and {{Linguistic Theories}} ({{TLT15}}), {{Bloomington}}, {{IN}}, {{USA}}, {{January}} 20-21, 2017},
  author = {Croft, William and Nordquist, Dawn and Looney, Katherine and Regan, Michael},
  editor = {Dickinson, Markus and Hajic, Jan and Kübler, Sandra and Przepiórkowski, Adam},
  date = {2017},
  series = {{{CEUR Workshop Proceedings}}},
  volume = {1779},
  pages = {63--75},
  publisher = {{CEUR-WS.org}},
  url = {http://ceur-ws.org/Vol-1779/05croft.pdf},
  urldate = {2022-08-22},
  file = {/Users/siyu/Zotero/storage/P5XI46RD/Croft et al. - Linguistic Typology Meets Universal Dependencies.pdf}
}

@article{demarneffe2019,
  title = {Dependency Grammar},
  author = {de Marneffe, Marie-Catherine and Nivre, Joakim},
  options = {useprefix=true},
  date = {2019},
  journaltitle = {Annual Review of Linguistics},
  volume = {5},
  number = {1},
  eprint = {https://doi.org/10.1146/annurev-linguistics-011718-011842},
  pages = {197--218},
  doi = {10.1146/annurev-linguistics-011718-011842},
  url = {https://doi.org/10.1146/annurev-linguistics-011718-011842},
  abstract = {Dependency grammar is a descriptive and theoretical tradition in linguistics that can be traced back to antiquity. It has long been influential in the European linguistics tradition and has more recently become a mainstream approach to representing syntactic and semantic structure in natural language processing. In this review, we introduce the basic theoretical assumptions of dependency grammar and review some key aspects in which different dependency frameworks agree or disagree. We also discuss advantages and disadvantages of dependency representations and introduce Universal Dependencies, a framework for multilingual dependency-based morphosyntactic annotation that has been applied to more than 60 languages.},
  file = {/Users/siyu/Zotero/storage/BGZZ5F7M/de Marneffe and Nivre - 2018 - Dependency Grammar.pdf}
}

@article{demarneffe2021,
  title = {Universal {{Dependencies}}},
  author = {de Marneffe, Marie-Catherine and Manning, Christopher D. and Nivre, Joakim and Zeman, Daniel},
  options = {useprefix=true},
  date = {2021-07-13},
  journaltitle = {Computational Linguistics},
  shortjournal = {Computational Linguistics},
  volume = {47},
  number = {2},
  pages = {255--308},
  issn = {0891-2017},
  doi = {10.1162/coli_a_00402},
  url = {https://doi.org/10.1162/coli_a_00402},
  urldate = {2022-08-22},
  abstract = {Universal dependencies (UD) is a framework for morphosyntactic annotation of human language, which to date has been used to create treebanks for more than 100 languages. In this article, we outline the linguistic theory of the UD framework, which draws on a long tradition of typologically oriented grammatical theories. Grammatical relations between words are centrally used to explain how predicate–argument structures are encoded morphosyntactically in different languages while morphological features and part-of-speech classes give the properties of words. We argue that this theory is a good basis for crosslinguistically consistent annotation of typologically diverse languages in a way that supports computational natural language understanding as well as broader linguistic studies.},
  file = {/Users/siyu/Zotero/storage/N5YYIWQS/de Marneffe et al. - 2021 - Universal Dependencies.pdf;/Users/siyu/Zotero/storage/AA3Y5KYU/Universal-Dependencies.html}
}

@article{dowty1991,
  title = {Thematic {{Proto-Roles}} and {{Argument Selection}}},
  author = {Dowty, David},
  date = {1991},
  journaltitle = {Language},
  volume = {67},
  number = {3},
  eprint = {415037},
  eprinttype = {jstor},
  pages = {547--619},
  issn = {0097-8507},
  doi = {10.2307/415037},
  abstract = {As a novel attack on the perennially vexing questions of the theoretical status of thematic roles and the inventory of possible roles, this paper defends a strategy of basing accounts of roles on more unified domains of linguistic data than have been used in the past to motivate roles, addressing in particular the problem of ARGUMENT SELECTION (principles determining which roles are associated with which grammatical relations). It is concluded that the best theory for describing this domain is not a traditional system of discrete roles (Agent, Patient, Source, etc.) but a theory in which the only roles are two cluster-concepts called Proto-Agent and Proto-Patient, each characterized by a set of verbal entailments: an argument of a verb may bear either of the two proto-roles (or both) to varying degrees, according to the number of entailments of each kind the verb gives it. Both fine-grained and coarse-grained classes of verbal arguments (corresponding to traditional thematic roles and other classes as well) follow automatically, as do desired 'role hierarchies'. By examining occurrences of the 'same' verb with different argument configurations-e.g. two forms of psych predicates and object-oblique alternations as in the familiar spray/load class-it can also be argued that proto-roles act as defaults in the learning of lexical meanings. Are proto-role categories manifested else-where in language or as cognitive categories? If so, they might be a means of making grammar acquisition easier for the child, they might explain certain other typological and acquisitional observations, and they may lead to an account of contrasts between unaccusative and unergative intransitive verbs that does not rely on deriving unaccusatives from underlying direct objects.},
  file = {/Users/siyu/Zotero/storage/PI4SEDIM/Dowty - 1991 - Thematic Proto-Roles and Argument Selection.pdf}
}

@inproceedings{dubossarsky2017,
  title = {Outta {{Control}}: {{Laws}} of {{Semantic Change}} and {{Inherent Biases}} in {{Word Representation Models}}},
  shorttitle = {Outta {{Control}}},
  booktitle = {Proceedings of the 2017 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Dubossarsky, Haim and Weinshall, Daphna and Grossman, Eitan},
  date = {2017-09},
  pages = {1136--1145},
  publisher = {{Association for Computational Linguistics}},
  location = {{Copenhagen, Denmark}},
  doi = {10.18653/v1/D17-1118},
  url = {https://aclanthology.org/D17-1118},
  urldate = {2022-05-11},
  abstract = {This article evaluates three proposed laws of semantic change. Our claim is that in order to validate a putative law of semantic change, the effect should be observed in the genuine condition but absent or reduced in a suitably matched control condition, in which no change can possibly have taken place. Our analysis shows that the effects reported in recent literature must be substantially revised: (i) the proposed negative correlation between meaning change and word frequency is shown to be largely an artefact of the models of word representation used; (ii) the proposed negative correlation between meaning change and prototypicality is shown to be much weaker than what has been claimed in prior art; and (iii) the proposed positive correlation between meaning change and polysemy is largely an artefact of word frequency. These empirical observations are corroborated by analytical proofs that show that count representations introduce an inherent dependence on word frequency, and thus word frequency cannot be evaluated as an independent factor with these representations.},
  eventtitle = {{{EMNLP}} 2017},
  file = {/Users/siyu/Zotero/storage/KT8Z4LVX/Dubossarsky et al. - 2017 - Outta Control Laws of Semantic Change and Inheren.pdf}
}

@thesis{dubossarsky2018,
  type = {PhD Thesis in Brain Sciences: Computation and Information Processing},
  title = {Semantic Change at Large: {{A}} Computational Approach for Semantic Change Research},
  author = {Dubossarsky, Haim},
  date = {2018-04},
  institution = {{Hebrew University of Jerusalem}},
  location = {{Jerusalem}},
  url = {https://www.cs.huji.ac.il/w~daphna/theses/Haim_Dubossarsky_2018.pdf},
  urldate = {2022-05-11},
  file = {/Users/siyu/Zotero/storage/RCTCRNQW/Dubossarsky - 2018 - Semantic change at large A computational approach.pdf}
}

@inproceedings{dubossarsky2019,
  title = {Time-{{Out}}: {{Temporal Referencing}} for {{Robust Modeling}} of {{Lexical Semantic Change}}},
  shorttitle = {Time-{{Out}}},
  booktitle = {Proceedings of the 57th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Dubossarsky, Haim and Hengchen, Simon and Tahmasebi, Nina and Schlechtweg, Dominik},
  date = {2019-07},
  pages = {457--470},
  publisher = {{Association for Computational Linguistics}},
  location = {{Florence, Italy}},
  doi = {10.18653/v1/P19-1044},
  url = {https://aclanthology.org/P19-1044},
  urldate = {2022-05-11},
  abstract = {State-of-the-art models of lexical semantic change detection suffer from noise stemming from vector space alignment. We have empirically tested the Temporal Referencing method for lexical semantic change and show that, by avoiding alignment, it is less affected by this noise. We show that, trained on a diachronic corpus, the skip-gram with negative sampling architecture with temporal referencing outperforms alignment models on a synthetic task as well as a manual testset. We introduce a principled way to simulate lexical semantic change and systematically control for possible biases.},
  eventtitle = {{{ACL}} 2019},
  file = {/Users/siyu/Zotero/storage/QJ4QQIP9/Dubossarsky et al. - 2019 - Time-Out Temporal Referencing for Robust Modeling.pdf}
}

@inproceedings{ellsworth2021,
  title = {{{FrameNet}} and {{Typology}}},
  booktitle = {Proceedings of the {{Third Workshop}} on {{Computational Typology}} and {{Multilingual NLP}}},
  author = {Ellsworth, Michael and Baker, Collin and Petruck, Miriam R. L.},
  date = {2021},
  pages = {61--66},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online}},
  doi = {10.18653/v1/2021.sigtyp-1.6},
  url = {https://www.aclweb.org/anthology/2021.sigtyp-1.6},
  urldate = {2021-11-01},
  eventtitle = {Proceedings of the {{Third Workshop}} on {{Computational Typology}} and {{Multilingual NLP}}},
  langid = {english},
  file = {/Users/siyu/Zotero/storage/UKJGZ7RL/Ellsworth et al. - 2021 - FrameNet and Typology.pdf}
}

@book{faulhaber2011,
  title = {Verb {{Valency Patterns}}: {{A Challenge}} for {{Semantics-Based Accounts}}},
  shorttitle = {Verb {{Valency Patterns}}},
  author = {Faulhaber, Susen},
  date = {2011-04-29},
  journaltitle = {Verb Valency Patterns},
  publisher = {{De Gruyter Mouton}},
  doi = {10.1515/9783110240788},
  url = {https://www.degruyter.com/document/doi/10.1515/9783110240788/html},
  urldate = {2022-09-18},
  abstract = {Taking as its point of departure the general assumption that meaning is crucial in accounting for verb complementation, this volume presents the results of an empirical study of verb complementation patterns of semantically similar English verbs. The semantic parallels of the verbs selected are based on their coverage in dictionaries - first and foremost the Valency Dictionary of English (Herbst, Heath, Roe and Götz 2004) - as well as corpus research and native speaker assessments. It is demonstrated that despite obvious similarities in complementation between such verbs, there are still a significant number of syntactic discrepancies which cannot be accounted for on the basis of meaning alone and that semantic factors - such as selection restrictions and aspectual properties - do not sufficiently correlate with the verbs' syntactic properties and consequently do not have sufficient explanatory power. Thus the results rigorously challenge so-called projectionist approaches which assume the position that complementation is determined by semantic properties and thus ought to be predictable on this basis. In the light of a general trend towards placing greater emphasis on semantic aspects, in the fields of construction grammar and cognitive grammar too, the number of idiosyncratic phenomena on the level of single complements as well as whole patterns clearly underlines the importance of storage phenomena as opposed to rule-based generation. As such it stresses the necessity of finding ways to systematically account for item-specific properties of verbs in any grammatical theory of the English language. The book is targeted at all linguists interested in the relationship between semantics and syntax, which is one of the prevalent questions in modern linguistics, also in the field of construction grammar and cognitive grammar. Since the data is presented in a way which is compatible with various theories of complementation, the target group is clearly not restricted to any specific linguistic school. Because of the large amount of item-specific information presented, this book is also a valuable source for grammarians and lexicographers.},
  isbn = {978-3-11-024078-8},
  langid = {english},
  keywords = {English/Language,Semantics,Syntax},
  file = {/Users/siyu/Zotero/storage/5HYCWLLK/Faulhaber - 2011 - Verb Valency Patterns A Challenge for Semantics-B.pdf}
}

@book{fedriani2020,
  title = {The {{Diachrony}} of {{Ditransitives}}},
  editor = {Fedriani, Chiara and Napoli, Maria},
  date = {2020-10-26},
  publisher = {{De Gruyter Mouton}},
  doi = {10.1515/9783110701371},
  url = {https://www.degruyter.com/document/doi/10.1515/9783110701371/html},
  urldate = {2022-11-16},
  abstract = {While ample studies exist on ditransitives in various languages, notably from a typological perspective, more work needs to be done on identifying the main processes and factors that trigger and constrain the changes they undergo over time. The goal of this volume is to help fill this gap by bringing together data and information on individual languages that have thus far been left out of the discussion and by expanding our knowledge of already studied linguistic traditions so as to achieve a broader diachronic description. Since one of the distinctive features of ditransitives is their synchronic variability in terms of structural alternation and alignment split, diachronic research can throw up new insights into developmental dynamics that are eminently complementary; namely, on the one hand, the emergence, development and loss of construction alternation and, on the other, the acquisition of new functions over time. The analyses offered in the book yield different and interconnected answers to the general question of how ditransitives change by drawing on different functional principles that play a role in the diachronic reorganization of this dynamic domain and by providing a number of original theoretical suggestions.},
  isbn = {978-3-11-070137-1},
  langid = {english},
  keywords = {Alignment Types,Argument Structure,Construction Alternation,Syntax-Semantics Interface},
  file = {/Users/siyu/Zotero/storage/F237B2AK/2020 - The Diachrony of Ditransitives.pdf}
}

@article{ferrer-i-cancho2017,
  title = {The {{Placement}} of the {{Head}} That {{Maximizes Predictability}}. {{An Information Theoretic Approach}}},
  author = {Ferrer-i-Cancho, Ramon},
  date = {2017},
  journaltitle = {Glottometrics},
  number = {39},
  pages = {38--71},
  abstract = {The minimization of the length of syntactic dependencies is a well-established principle of word order and the basis of a mathematical theory of word order. Here we complete that theory from the perspective of information theory, adding a competing word order principle: the maximization of predictability of a target element. These two principles are in conflict: to maximize the predictability of the head, the head should appear last, which maximizes the costs with respect to dependency length minimization. The implications of such a broad theoretical framework to understand the optimality, diversity and evolution of the six possible orderings of subject, object and verb, are reviewed.},
  langid = {english},
  file = {/Users/siyu/Zotero/storage/IT54D7AM/Ferrer-i-Cancho - The Placement of the Head that Maximizes Predictab.pdf}
}

@article{fillmore1967,
  title = {The {{Case}} for {{Case}}},
  author = {Fillmore, Charles J.},
  date = {1967},
  file = {/Users/siyu/Zotero/storage/K9HIFFAK/Fillmore - 1967 - The Case for Case.pdf}
}

@article{fillmore1970,
  title = {The {{Grammar}} of {{HITTING}} and {{BREAKING}}},
  author = {Fillmore, Charles J.},
  date = {1970},
  url = {https://www1.icsi.berkeley.edu/pubs/ai/ICSI_grammarofhitting12.pdf},
  urldate = {2022-09-18},
  file = {/Users/siyu/Zotero/storage/2UN8KSVF/Fillmore - 1970 - The Grammar of HITTING and BREAKING.pdf}
}

@inproceedings{furstenau2012,
  title = {Unsupervised {{Induction}} of a {{Syntax-Semantics Lexicon Using Iterative Refinement}}},
  booktitle = {*{{SEM}} 2012: {{The First Joint Conference}} on {{Lexical}} and {{Computational Semantics}} – {{Volume}} 1: {{Proceedings}} of the Main Conference and the Shared Task, and {{Volume}} 2: {{Proceedings}} of the {{Sixth International Workshop}} on {{Semantic Evaluation}} ({{SemEval}} 2012)},
  author = {Fürstenau, Hagen and Rambow, Owen},
  date = {2012},
  pages = {180--188},
  publisher = {{Association for Computational Linguistics}},
  location = {{Montréal, Canada}},
  url = {https://www.aclweb.org/anthology/S12-1026},
  urldate = {2019-09-18},
  eventtitle = {*{{SEM}}/{{SemEval}} 2012},
  file = {/Users/siyu/Zotero/storage/D2JNXCYI/Fürstenau and Rambow - 2012 - Unsupervised Induction of a Syntax-Semantics Lexic.pdf}
}

@article{futrell2015,
  title = {Large-Scale Evidence of Dependency Length Minimization in 37 Languages},
  author = {Futrell, Richard and Mahowald, Kyle and Gibson, Edward},
  date = {2015-08-18},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {Proc Natl Acad Sci USA},
  volume = {112},
  number = {33},
  pages = {10336--10341},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1502134112},
  url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1502134112},
  urldate = {2021-10-29},
  abstract = {Explaining the variation between human languages and the constraints on that variation is a core goal of linguistics. In the last 20 y, it has been claimed that many striking universals of cross-linguistic variation follow from a hypothetical principle that dependency length—the distance between syntactically related words in a sentence—is minimized. Various models of human sentence production and comprehension predict that long dependencies are difficult or inefficient to process; minimizing dependency length thus enables effective communication without incurring processing difficulty. However, despite widespread application of this idea in theoretical, empirical, and practical work, there is not yet large-scale evidence that dependency length is actually minimized in real utterances across many languages; previous work has focused either on a small number of languages or on limited kinds of data about each language. Here, using parsed corpora of 37 diverse languages, we show that overall dependency lengths for all languages are shorter than conservative random baselines. The results strongly suggest that dependency length minimization is a universal quantitative property of human languages and support explanations of linguistic variation in terms of general properties of human information processing.},
  langid = {english},
  file = {/Users/siyu/Zotero/storage/7HUH9FZQ/Futrell et al. - 2015 - Large-scale evidence of dependency length minimiza.pdf}
}

@inproceedings{futrell2015a,
  title = {Quantifying {{Word Order Freedom}} in {{Dependency Corpora}}},
  booktitle = {Proceedings of the {{Third International Conference}} on {{Dependency Linguistics}} ({{Depling}} 2015)},
  author = {Futrell, Richard and Mahowald, Kyle and Gibson, Edward},
  date = {2015-08},
  pages = {91--100},
  publisher = {{Uppsala University, Uppsala, Sweden}},
  location = {{Uppsala, Sweden}},
  url = {https://aclanthology.org/W15-2112},
  urldate = {2022-07-12},
  file = {/Users/siyu/Zotero/storage/3T4VHNSY/Futrell et al. - 2015 - Quantifying Word Order Freedom in Dependency Corpo.pdf}
}

@inproceedings{futrell2019,
  title = {Syntactic Dependencies Correspond to Word Pairs with High Mutual Information},
  booktitle = {Proceedings of the {{Fifth International Conference}} on {{Dependency Linguistics}} ({{Depling}}, {{SyntaxFest}} 2019)},
  author = {Futrell, Richard and Qian, Peng and Gibson, Edward and Fedorenko, Evelina and Blank, Idan},
  date = {2019-08},
  pages = {3--13},
  publisher = {{Association for Computational Linguistics}},
  location = {{Paris, France}},
  doi = {10.18653/v1/W19-7703},
  url = {https://aclanthology.org/W19-7703},
  urldate = {2022-07-12},
  file = {/Users/siyu/Zotero/storage/BRS4BVM8/Futrell et al. - 2019 - Syntactic dependencies correspond to word pairs wi.pdf}
}

@inproceedings{futrell2019a,
  title = {Information-Theoretic Locality Properties of Natural Language},
  booktitle = {Proceedings of the {{First Workshop}} on {{Quantitative Syntax}} ({{Quasy}}, {{SyntaxFest}} 2019)},
  author = {Futrell, Richard},
  date = {2019-08},
  pages = {2--15},
  publisher = {{Association for Computational Linguistics}},
  location = {{Paris, France}},
  doi = {10.18653/v1/W19-7902},
  url = {https://aclanthology.org/W19-7902},
  urldate = {2022-07-26},
  file = {/Users/siyu/Zotero/storage/C7Z8FSHB/Futrell - 2019 - Information-theoretic locality properties of natur.pdf}
}

@article{futrell2020,
  title = {Dependency Locality as an Explanatory Principle for Word Order},
  author = {Futrell, Richard and Levy, Roger P. and Gibson, Edward},
  date = {2020},
  journaltitle = {Language},
  shortjournal = {Language},
  volume = {96},
  number = {2},
  pages = {371--412},
  issn = {1535-0665},
  doi = {10.1353/lan.2020.0024},
  url = {https://muse.jhu.edu/article/757632},
  urldate = {2022-07-26},
  langid = {english},
  file = {/Users/siyu/Zotero/storage/L95GH2WS/Futrell et al. - 2020 - Dependency locality as an explanatory principle fo.pdf}
}

@article{gibson2019,
  title = {How {{Efficiency Shapes Human Language}}},
  author = {Gibson, Edward and Futrell, Richard and Piantadosi, Steven P. and Dautriche, Isabelle and Mahowald, Kyle and Bergen, Leon and Levy, Roger},
  date = {2019-05-01},
  journaltitle = {Trends in Cognitive Sciences},
  shortjournal = {Trends in Cognitive Sciences},
  volume = {23},
  number = {5},
  pages = {389--407},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2019.02.003},
  url = {https://www.sciencedirect.com/science/article/pii/S1364661319300580},
  urldate = {2022-07-12},
  abstract = {Cognitive science applies diverse tools and perspectives to study human language. Recently, an exciting body of work has examined linguistic phenomena through the lens of efficiency in usage: what otherwise puzzling features of language find explanation in formal accounts of how language might be optimized for communication and learning? Here, we review studies that deploy formal tools from probability and information theory to understand how and why language works the way that it does, focusing on phenomena ranging from the lexicon through syntax. These studies show how a pervasive pressure for efficiency guides the forms of natural language and indicate that a rich future for language research lies in connecting linguistics to cognitive psychology and mathematical theories of communication and inference.},
  langid = {english},
  keywords = {communication,cross-linguistic universals,language complexity,language efficiency,language evolution,language learnability},
  file = {/Users/siyu/Zotero/storage/T7BLQ64N/Gibson et al. - 2019 - How Efficiency Shapes Human Language.pdf;/Users/siyu/Zotero/storage/P98LU28I/S1364661319300580.html}
}

@misc{gonen2022,
  title = {Analyzing {{Gender Representation}} in {{Multilingual Models}}},
  author = {Gonen, Hila and Ravfogel, Shauli and Goldberg, Yoav},
  date = {2022-04-19},
  number = {arXiv:2204.09168},
  eprint = {2204.09168},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2204.09168},
  urldate = {2022-05-18},
  abstract = {Multilingual language models were shown to allow for nontrivial transfer across scripts and languages. In this work, we study the structure of the internal representations that enable this transfer. We focus on the representation of gender distinctions as a practical case study, and examine the extent to which the gender concept is encoded in shared subspaces across different languages. Our analysis shows that gender representations consist of several prominent components that are shared across languages, alongside language-specific components. The existence of language-independent and language-specific components provides an explanation for an intriguing empirical observation we make: while gender classification transfers well across languages, interventions for gender removal, trained on a single language, do not transfer easily to others.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/siyu/Zotero/storage/9FDMTPRX/Gonen et al. - 2022 - Analyzing Gender Representation in Multilingual Mo.pdf}
}

@incollection{greenberg1963,
  title = {Some Universals of Grammar with Particular Reference to the Order of Meaningful Elements},
  booktitle = {Universals of {{Language}}},
  author = {Greenberg, Joseph},
  date = {1963},
  pages = {73--113},
  publisher = {{mit Press}},
  location = {{Cambridge, MA}},
  file = {/Users/siyu/Zotero/storage/CZ622N9K/Greenberg - 1963 - Some universals of grammar with particular referen.pdf}
}

@article{hahn2021,
  title = {Modeling Word and Morpheme Order in Natural Language as an Efficient Trade-off of Memory and Surprisal},
  author = {Hahn, Michael and Degen, Judith and Futrell, Richard},
  date = {2021},
  journaltitle = {Psychological Review},
  volume = {128},
  number = {4},
  pages = {726--756},
  publisher = {{American Psychological Association}},
  location = {{US}},
  issn = {1939-1471},
  doi = {10.1037/rev0000269},
  abstract = {Memory limitations are known to constrain language comprehension and production, and have been argued to account for crosslinguistic word order regularities. However, a systematic assessment of the role of memory limitations in language structure has proven elusive, in part because it is hard to extract precise large-scale quantitative generalizations about language from existing mechanistic models of memory use in sentence processing. We provide an architecture-independent information-theoretic formalization of memory limitations which enables a simple calculation of the memory efficiency of languages. Our notion of memory efficiency is based on the idea of a memory–surprisal trade-off: A certain level of average surprisal per word can only be achieved at the cost of storing some amount of information about the past context. Based on this notion of memory usage, we advance the Efficient Trade-off Hypothesis: The order of elements in natural language is under pressure to enable favorable memory–surprisal trade-offs. We derive that languages enable more efficient trade-offs when they exhibit information locality: When predictive information about an element is concentrated in its recent past. We provide empirical evidence from three test domains in support of the Efficient Trade-off Hypothesis: A reanalysis of a miniature artificial language learning experiment, a large-scale study of word order in corpora of 54 languages, and an analysis of morpheme order in two agglutinative languages. These results suggest that principles of order in natural language can be explained via highly generic cognitively motivated principles and lend support to efficiency-based models of the structure of human language. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  keywords = {Hypothesis Testing,Information Theory,Memory,Morphemes,Natural Language,Prediction,Sentence Comprehension,Simulation},
  file = {/Users/siyu/Zotero/storage/9VI6UG9T/Hahn et al. - 2021 - Modeling word and morpheme order in natural langua.pdf;/Users/siyu/Zotero/storage/JSL59FWX/2021-31510-001.html}
}

@article{hahn2022,
  title = {Crosslinguistic Word Order Variation Reflects Evolutionary Pressures of Dependency and Information Locality},
  author = {Hahn, Michael and Xu, Yang},
  date = {2022-06-14},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {119},
  number = {24},
  pages = {e2122604119},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.2122604119},
  url = {https://www.pnas.org/doi/10.1073/pnas.2122604119},
  urldate = {2022-07-27},
  file = {/Users/siyu/Zotero/storage/9Z9FY9KV/Hahn and Xu - 2022 - Crosslinguistic word order variation reflects evol.pdf;/Users/siyu/Zotero/storage/ZV4YMKHM/pnas.2122604119.sapp.pdf}
}

@article{hahn2022a,
  title = {Morpheme {{Ordering Across Languages Reflects Optimization}} for {{Processing Efficiency}}},
  author = {Hahn, Michael and Mathew, Rebecca and Degen, Judith},
  date = {2022-02-09},
  journaltitle = {Open Mind},
  shortjournal = {Open Mind},
  volume = {5},
  pages = {208--232},
  issn = {2470-2986},
  doi = {10.1162/opmi_a_00051},
  url = {https://doi.org/10.1162/opmi_a_00051},
  urldate = {2022-07-27},
  abstract = {The ordering of morphemes in a word displays well-documented regularities across languages. Previous work has explained these in terms of notions such as semantic scope, relevance, and productivity. Here, we test a recently formulated processing theory of the ordering of linguistic units, the efficient tradeoff hypothesis (Hahn et al., 2021). The claim of the theory is that morpheme ordering can partly be explained by the optimization of a tradeoff between memory and surprisal. This claim has received initial empirical support from two languages. In this work, we test this idea more extensively using data from four additional agglutinative languages with significant amounts of morphology, and by considering nouns in addition to verbs. We find that the efficient tradeoff hypothesis predicts ordering in most cases with high accuracy, and accounts for cross-linguistic regularities in noun and verb inflection. Our work adds to a growing body of work suggesting that many ordering properties of language arise from a pressure for efficient language processing.},
  file = {/Users/siyu/Zotero/storage/IW6JXY6P/Hahn et al. - 2022 - Morpheme Ordering Across Languages Reflects Optimi.pdf;/Users/siyu/Zotero/storage/Y4WZDMSY/Morpheme-Ordering-Across-Languages-Reflects.html}
}

@book{hale2002,
  title = {Prolegomenon to a Theory of Argument Structure},
  author = {Hale, Kenneth L and Keyser, Samuel Jay and {MIT Press}},
  date = {2002},
  publisher = {{The MIT Press}},
  location = {{Cambridge; London}},
  isbn = {978-0-262-08308-9 978-0-262-58214-8},
  langid = {english},
  annotation = {OCLC: 909967097},
  file = {/Users/siyu/Zotero/storage/6DXQI8T8/Hale et al. - 2006 - Prolegomenon to a theory of argument structure.pdf}
}

@inproceedings{hamilton2016,
  title = {Diachronic {{Word Embeddings Reveal Statistical Laws}} of {{Semantic Change}}},
  booktitle = {Proceedings of the 54th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Hamilton, William L. and Leskovec, Jure and Jurafsky, Dan},
  date = {2016-08},
  pages = {1489--1501},
  publisher = {{Association for Computational Linguistics}},
  location = {{Berlin, Germany}},
  doi = {10.18653/v1/P16-1141},
  url = {https://aclanthology.org/P16-1141},
  urldate = {2022-05-11},
  eventtitle = {{{ACL}} 2016},
  file = {/Users/siyu/Zotero/storage/DJ8KYY5R/Hamilton et al. - 2016 - Diachronic Word Embeddings Reveal Statistical Laws.pdf}
}

@inproceedings{hamilton2016a,
  title = {Cultural {{Shift}} or {{Linguistic Drift}}? {{Comparing Two Computational Measures}} of {{Semantic Change}}},
  shorttitle = {Cultural {{Shift}} or {{Linguistic Drift}}?},
  booktitle = {Proceedings of the 2016 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Hamilton, William L. and Leskovec, Jure and Jurafsky, Dan},
  date = {2016-11},
  pages = {2116--2121},
  publisher = {{Association for Computational Linguistics}},
  location = {{Austin, Texas}},
  doi = {10.18653/v1/D16-1229},
  url = {https://aclanthology.org/D16-1229},
  urldate = {2022-05-11},
  eventtitle = {{{EMNLP}} 2016},
  file = {/Users/siyu/Zotero/storage/X3S5T22S/Hamilton et al. - 2016 - Cultural Shift or Linguistic Drift Comparing Two .pdf}
}

@inbook{haspelmath2015,
  title = {Transitivity Prominence},
  booktitle = {Valency Classes in the {{World}}'s Languages: {{Volume}} 1 {{Introducing}} the Framework, and Case Studies from {{Africa}} and {{Eurasia}}},
  author = {Haspelmath, Martin},
  date = {2015},
  volume = {1},
  pages = {131--147},
  publisher = {{De Gruyter Mouton}},
  location = {{Berlin; Boston}},
  bookauthor = {Malchukov, Andrej and Comrie, Bernard},
  isbn = {978-3-11-033294-0},
  langid = {english},
  volumes = {2},
  annotation = {OCLC: 1015602777}
}

@inproceedings{he2017,
  title = {Deep {{Semantic Role Labeling}}: {{What Works}} and {{What}}'s {{Next}}},
  shorttitle = {Deep {{Semantic Role Labeling}}},
  booktitle = {Proceedings of the 55th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {He, Luheng and Lee, Kenton and Lewis, Mike and Zettlemoyer, Luke},
  date = {2017-07},
  pages = {473--483},
  publisher = {{Association for Computational Linguistics}},
  location = {{Vancouver, Canada}},
  doi = {10.18653/v1/P17-1044},
  url = {https://aclanthology.org/P17-1044},
  urldate = {2022-06-07},
  abstract = {We introduce a new deep learning model for semantic role labeling (SRL) that significantly improves the state of the art, along with detailed analyses to reveal its strengths and limitations. We use a deep highway BiLSTM architecture with constrained decoding, while observing a number of recent best practices for initialization and regularization. Our 8-layer ensemble model achieves 83.2 F1 on theCoNLL 2005 test set and 83.4 F1 on CoNLL 2012, roughly a 10\% relative error reduction over the previous state of the art. Extensive empirical analysis of these gains show that (1) deep models excel at recovering long-distance dependencies but can still make surprisingly obvious errors, and (2) that there is still room for syntactic parsers to improve these results.},
  eventtitle = {{{ACL}} 2017},
  file = {/Users/siyu/Zotero/storage/UV2RNNG6/He et al. - 2017 - Deep Semantic Role Labeling What Works and What's.pdf}
}

@inproceedings{hellan2014,
  title = {{{MultiVal}} - towards a Multilingual Valence Lexicon},
  booktitle = {Proceedings of the {{Ninth International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}}'14)},
  author = {Hellan, Lars and Beermann, Dorothee and Bruland, Tore and Dakubu, Mary Esther Kropp and Marimon, Montserrat},
  date = {2014-05},
  pages = {2478--2485},
  publisher = {{European Language Resources Association (ELRA)}},
  location = {{Reykjavik, Iceland}},
  url = {http://www.lrec-conf.org/proceedings/lrec2014/pdf/1179_Paper.pdf},
  urldate = {2022-09-25},
  abstract = {MultiVal is a valence lexicon derived from lexicons of computational HPSG grammars for Norwegian, Spanish and Ga (ISO 639-3, gaa), with altogether about 22,000 verb entries and on average more than 200 valence types defined for each language. These lexical resources are mapped onto a common set of discriminants with a common array of values, and stored in a relational database linked to a web demo and a wiki presentation. Search discriminants are syntactic argument structure (SAS), functional specification, situation type and aspect, for any subset of languages, as well as the verb type systems of the grammars. Search results are lexical entries satisfying the discriminants entered, exposing the specifications from the respective provenance grammars. The Ga grammar lexicon has in turn been converted from a Ga Toolbox lexicon. Aside from the creation of such a multilingual valence resource through converging or converting existing resources, the paper also addresses a tool for the creation of such a resource as part of corpus annotation for less resourced languages.},
  eventtitle = {{{LREC}} 2014},
  file = {/Users/siyu/Zotero/storage/WZ44DK3H/Hellan et al. - 2014 - MultiVal - towards a multilingual valence lexicon.pdf}
}

@book{hellan2017,
  title = {Contrastive Studies in Verbal Valency},
  editor = {Hellan, Lars and Malchukov, Andrej and Cennamo, Michela},
  date = {2017},
  publisher = {{John Benjamins}},
  url = {https://www.jbe-platform.com/content/books/9789027266095},
  abstract = {In recent years, issues of verbal valency, valency alternations and verb classes have seen a new upsurge of interest from a variety of perspectives. This book comprises articles investigating valency phenomena on a contrastive basis within Romance, Germanic and Slavic, and also in Basque and in the West-African language Ga, as well as classical Greek and Sanskrit. Phenomena include transitive and ditransitive constructions and alternations, involving reflexives, cognate objects, ’null’ objects, case (in its syntagmatic and paradigmatic aspects), and infinitives, mostly in a synchronic perspective. Aiming at a closer understanding of the range of regularities falling within the concept of valency frames, the book offers a representative array of current assumptions, hypotheses, methodologies and new findings within the overall field. The volume will provide a valuable resource for researchers and students both in general linguistics and in the relevant language particular disciplines.},
  file = {/Users/siyu/Zotero/storage/DI26W8C6/Hellan et al. - 2017 - Contrastive Studies in Verbal Valency.pdf}
}

@book{herbst2013,
  title = {A {{Valency Dictionary}} of {{English}}: {{A Corpus-Based Analysis}} of the {{Complementation Patterns}} of {{English Verbs}}, {{Nouns}} and {{Adjectives}}},
  shorttitle = {A {{Valency Dictionary}} of {{English}}},
  author = {Herbst, Thomas and Heath, David and Roe, Ian F. and Götz, Dieter},
  date = {2013-02-06},
  journaltitle = {A Valency Dictionary of English},
  publisher = {{De Gruyter Mouton}},
  doi = {10.1515/9783110892581},
  url = {https://www.degruyter.com/document/doi/10.1515/9783110892581/html?lang=en},
  urldate = {2022-09-18},
  abstract = {This dictionary provides a valency description of English verbs, nouns and adjectives. Each entry contains a comprehensive list of the complementation patterns identified on the basis of the largest corpus of English available at the present time. All examples are taken directly from the COBUILD/Birmingham corpus. The valency description comprises statements about the quantitative valency of the lexical units established, an inventory of their obligatory, contextually optional and purely optional complements as well as systematic information on the semantic and collocational properties of the complements. An outline of the model of valency theory used in this dictionary is provided in the introduction.},
  isbn = {978-3-11-089258-1},
  langid = {english},
  keywords = {dictionary,English/language,valency/lexicon},
  file = {/Users/siyu/Zotero/storage/LBWMDSCC/Herbst et al. - 2013 - A Valency Dictionary of English A Corpus-Based An.pdf}
}

@inproceedings{hoover2021,
  title = {Linguistic {{Dependencies}} and {{Statistical Dependence}}},
  booktitle = {Proceedings of the 2021 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Hoover, Jacob Louis and Du, Wenyu and Sordoni, Alessandro and O'Donnell, Timothy J.},
  date = {2021-11},
  pages = {2941--2963},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online and Punta Cana, Dominican Republic}},
  doi = {10.18653/v1/2021.emnlp-main.234},
  url = {https://aclanthology.org/2021.emnlp-main.234},
  urldate = {2022-07-12},
  abstract = {Are pairs of words that tend to occur together also likely to stand in a linguistic dependency? This empirical question is motivated by a long history of literature in cognitive science, psycholinguistics, and NLP. In this work we contribute an extensive analysis of the relationship between linguistic dependencies and statistical dependence between words. Improving on previous work, we introduce the use of large pretrained language models to compute contextualized estimates of the pointwise mutual information between words (CPMI). For multiple models and languages, we extract dependency trees which maximize CPMI, and compare to gold standard linguistic dependencies. Overall, we find that CPMI dependencies achieve an unlabelled undirected attachment score of at most \$\textbackslash approx 0.5\$. While far above chance, and consistently above a non-contextualized PMI baseline, this score is generally comparable to a simple baseline formed by connecting adjacent words. We analyze which kinds of linguistic dependencies are best captured in CPMI dependencies, and also find marked differences between the estimates of the large pretrained language models, illustrating how their different training schemes affect the type of dependencies they capture.},
  eventtitle = {{{EMNLP}} 2021},
  file = {/Users/siyu/Zotero/storage/KK56B2LC/Hoover et al. - 2021 - Linguistic Dependencies and Statistical Dependence.pdf}
}

@inproceedings{immer2022,
  title = {Probing as {{Quantifying Inductive Bias}}},
  booktitle = {Proceedings of the 60th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Immer, Alexander and Torroba Hennigen, Lucas and Fortuin, Vincent and Cotterell, Ryan},
  date = {2022-05},
  pages = {1839--1851},
  publisher = {{Association for Computational Linguistics}},
  location = {{Dublin, Ireland}},
  doi = {10.18653/v1/2022.acl-long.129},
  url = {https://aclanthology.org/2022.acl-long.129},
  urldate = {2022-06-06},
  abstract = {Pre-trained contextual representations have led to dramatic performance improvements on a range of downstream tasks. Such performance improvements have motivated researchers to quantify and understand the linguistic information encoded in these representations. In general, researchers quantify the amount of linguistic information through probing, an endeavor which consists of training a supervised model to predict a linguistic property directly from the contextual representations. Unfortunately, this definition of probing has been subject to extensive criticism in the literature, and has been observed to lead to paradoxical and counter-intuitive results. In the theoretical portion of this paper, we take the position that the goal of probing ought to be measuring the amount of inductive bias that the representations encode on a specific task. We further describe a Bayesian framework that operationalizes this goal and allows us to quantify the representations' inductive bias. In the empirical portion of the paper, we apply our framework to a variety of NLP tasks. Our results suggest that our proposed framework alleviates many previous problems found in probing. Moreover, we are able to offer concrete evidence that—for some tasks—fastText can offer a better inductive bias than BERT.},
  eventtitle = {{{ACL}} 2022},
  file = {/Users/siyu/Zotero/storage/RU78XZ3K/Immer et al. - 2022 - Probing as Quantifying Inductive Bias.pdf}
}

@article{jaeger2010,
  title = {Redundancy and Reduction: {{Speakers}} Manage Syntactic Information Density},
  shorttitle = {Redundancy and Reduction},
  author = {Jaeger, T. Florian},
  date = {2010-08-01},
  journaltitle = {Cognitive Psychology},
  shortjournal = {Cognitive Psychology},
  volume = {61},
  number = {1},
  pages = {23--62},
  issn = {0010-0285},
  doi = {10.1016/j.cogpsych.2010.02.002},
  url = {https://www.sciencedirect.com/science/article/pii/S0010028510000083},
  urldate = {2022-07-12},
  abstract = {A principle of efficient language production based on information theoretic considerations is proposed: Uniform Information Density predicts that language production is affected by a preference to distribute information uniformly across the linguistic signal. This prediction is tested against data from syntactic reduction. A single multilevel logit model analysis of naturally distributed data from a corpus of spontaneous speech is used to assess the effect of information density on complementizer that-mentioning, while simultaneously evaluating the predictions of several influential alternative accounts: availability, ambiguity avoidance, and dependency processing accounts. Information density emerges as an important predictor of speakers’ preferences during production. As information is defined in terms of probabilities, it follows that production is probability-sensitive, in that speakers’ preferences are affected by the contextual probability of syntactic structures. The merits of a corpus-based approach to the study of language production are discussed as well.},
  langid = {english},
  keywords = {Complementizer -mentioning,Efficient language production,Rational cognition,Syntactic production,Syntactic reduction},
  file = {/Users/siyu/Zotero/storage/YQU49NRX/Florian Jaeger - 2010 - Redundancy and reduction Speakers manage syntacti.pdf;/Users/siyu/Zotero/storage/A7UIDXBG/S0010028510000083.html}
}

@misc{jing2021,
  title = {Dependency Length Minimization and Its Limits: A Possible Role for a Probabilistic Version of the {{Final-Over-Final Condition}} (to Appear in {{Language}})},
  shorttitle = {Dependency Length Minimization and Its Limits},
  author = {Jing, Yingqi and Blasi, Damián and Bickel, Balthasar},
  date = {2021-09-13T08:27:45},
  publisher = {{PsyArXiv}},
  doi = {10.31234/osf.io/sp7r2},
  url = {https://psyarxiv.com/sp7r2/},
  urldate = {2022-07-13},
  abstract = {A prominent principle in explaining a range of word order regularities is dependency locality, i.e. a principle that minimizes the linear distances (dependency lengths) between the head and its dependents. However, it remains unclear to what extent language users in fact observe locality when producing sentences under diverse conditions of cross-categorical harmony (such as the placement of verbal and nominal heads on the same vs different sides of their dependents), dependency direction (head-final vs head-initial) and parallel vs. hierarchical dependency structures (e.g. multiple adjectives dependent on the same head vs nested genitive dependents). Using 45 dependency-annotated corpora of diverse languages, we find that after controlling for harmony and conditioning on dependency types, dependency length minimization (DLM) is inversely correlated with the overall presence of head-final dependencies. This anti-DLM effect in sentences with more head-final dependencies is specifically associated with an accumulation of dependents in parallel structures and with disharmonic orders in hierarchical structures. We propose a detailed interpretation of these results and tentatively suggest a role for a probabilistic principle that favors embedding head-initial (e.g. VO) structures inside equally head-initial and thereby length-minimizing structures (e.g. relative clauses after the head noun) while head-final (OV) structures have a less pronounced preference for harmony and DLM. This is in line with earlier findings in research on the Greenbergian word order universals and with a probabilistic version of what has been suggested as the Final-Over-Final Condition more recently.},
  langid = {american},
  keywords = {Cognitive Psychology,dependency length minimization,dependency treebanks,Final-Over-Final Condition,head-finality,Linguistics,Social and Behavioral Sciences,Syntax,Typological Linguistics and Linguistic Diversity,word order harmony},
  file = {/Users/siyu/Zotero/storage/MNMD6U86/Jing et al. - 2021 - Dependency length minimization and its limits a p.pdf}
}

@inproceedings{joulin2018,
  title = {Loss in {{Translation}}: {{Learning Bilingual Word Mapping}} with a {{Retrieval Criterion}}},
  shorttitle = {Loss in {{Translation}}},
  booktitle = {Proceedings of the 2018 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Joulin, Armand and Bojanowski, Piotr and Mikolov, Tomas and Jégou, Hervé and Grave, Edouard},
  date = {2018-10},
  pages = {2979--2984},
  publisher = {{Association for Computational Linguistics}},
  location = {{Brussels, Belgium}},
  doi = {10.18653/v1/D18-1330},
  url = {https://aclanthology.org/D18-1330},
  urldate = {2022-09-06},
  abstract = {Continuous word representations learned separately on distinct languages can be aligned so that their words become comparable in a common space. Existing works typically solve a quadratic problem to learn a orthogonal matrix aligning a bilingual lexicon, and use a retrieval criterion for inference. In this paper, we propose an unified formulation that directly optimizes a retrieval criterion in an end-to-end fashion. Our experiments on standard benchmarks show that our approach outperforms the state of the art on word translation, with the biggest improvements observed for distant language pairs such as English-Chinese.},
  eventtitle = {{{EMNLP}} 2018},
  file = {/Users/siyu/Zotero/storage/SXJQDQ2R/Joulin et al. - 2018 - Loss in Translation Learning Bilingual Word Mappi.pdf}
}

@inproceedings{kalm2019,
  title = {Event {{Structure Representation}}: {{Between Verbs}} and {{Argument Structure Constructions}}},
  shorttitle = {Event {{Structure Representation}}},
  booktitle = {Proceedings of the {{First International Workshop}} on {{Designing Meaning Representations}}},
  author = {Kalm, Pavlina and Regan, Michael and Croft, William},
  date = {2019-08},
  pages = {100--109},
  publisher = {{Association for Computational Linguistics}},
  location = {{Florence, Italy}},
  doi = {10.18653/v1/W19-3311},
  url = {https://aclanthology.org/W19-3311},
  urldate = {2022-06-20},
  abstract = {This paper proposes a novel representation of event structure by separating verbal semantics and the meaning of argument structure constructions that verbs occur in. Our model demonstrates how the two meaning representations interact. Our model thus effectively deals with various verb construals in different argument structure constructions, unlike purely verb-based approaches. However, unlike many constructionally-based approaches, we also provide a richer representation of the event structure evoked by the verb meaning.},
  file = {/Users/siyu/Zotero/storage/MCHHJJFG/Kalm et al. - 2019 - Event Structure Representation Between Verbs and .pdf}
}

@inproceedings{kim2014a,
  title = {Temporal {{Analysis}} of {{Language}} through {{Neural Language Models}}},
  booktitle = {Proceedings of the {{ACL}} 2014 {{Workshop}} on {{Language Technologies}} and {{Computational Social Science}}},
  author = {Kim, Yoon and Chiu, Yi-I and Hanaki, Kentaro and Hegde, Darshan and Petrov, Slav},
  date = {2014-06},
  pages = {61--65},
  publisher = {{Association for Computational Linguistics}},
  location = {{Baltimore, MD, USA}},
  doi = {10.3115/v1/W14-2517},
  url = {https://aclanthology.org/W14-2517},
  urldate = {2022-05-11},
  file = {/Users/siyu/Zotero/storage/5N8FT39L/Kim et al. - 2014 - Temporal Analysis of Language through Neural Langu.pdf}
}

@article{kipper2008,
  title = {A Large-Scale Classification of {{English}} Verbs},
  author = {Kipper, Karin and Korhonen, Anna and Ryant, Neville and Palmer, Martha},
  date = {2008-03-01},
  journaltitle = {Language Resources and Evaluation},
  shortjournal = {Lang Resources \& Evaluation},
  volume = {42},
  number = {1},
  pages = {21--40},
  issn = {1572-8412},
  doi = {10.1007/s10579-007-9048-2},
  url = {https://doi.org/10.1007/s10579-007-9048-2},
  urldate = {2019-09-18},
  abstract = {Lexical classifications have proved useful in supporting various natural language processing (NLP) tasks. The largest verb classification for English is Levin’s (1993) work which defines groupings of verbs based on syntactic and semantic properties. VerbNet (VN) (Kipper et al. 2000; Kipper-Schuler 2005)—an extensive computational verb lexicon for English—provides detailed syntactic-semantic descriptions of Levin classes. While the classes included are extensive enough for some NLP use, they are not comprehensive. Korhonen and Briscoe (2004) have proposed a significant extension of Levin’s classification which incorporates 57 novel classes for verbs not covered (comprehensively) by Levin. Korhonen and Ryant (unpublished) have recently proposed another extension including 53 additional classes. This article describes the integration of these two extensions into VN. The result is a comprehensive Levin-style classification for English verbs providing over 90\% token coverage of the Proposition Bank data (Palmer et al. 2005) and thus can be highly useful for practical applications.},
  langid = {english},
  keywords = {Computational linguistics,Lexical classification,Lexical resources},
  file = {/Users/siyu/Zotero/storage/2P37ZRNP/Kipper et al. - 2008 - A large-scale classification of English verbs.pdf}
}

@book{levin1993,
  title = {English Verb Classes and Alternations: A Preliminary Investigation},
  shorttitle = {English Verb Classes and Alternations},
  author = {Levin, Beth},
  date = {1993},
  publisher = {{Univ. of Chicago Press}},
  location = {{Chicago, Ill.}},
  isbn = {978-0-226-47532-5 978-0-226-47533-2},
  langid = {english},
  annotation = {OCLC: 634649485}
}

@book{levin2005a,
  title = {Argument {{Realization}}},
  author = {Levin, Beth and Rappaport Hovav, Malka},
  date = {2005},
  series = {Research {{Surveys}} in {{Linguistics}}},
  publisher = {{Cambridge University Press}},
  location = {{Cambridge}},
  doi = {10.1017/CBO9780511610479},
  url = {https://www.cambridge.org/core/books/argument-realization/8B1F52537D0D9EF4EB63B6AE30DDB6DE},
  urldate = {2022-11-08},
  abstract = {The relationship between verbs and their arguments is a widely debated topic in linguistics. This comprehensive 2005 survey provides an overview of this important area of research, exploring theories of how a verb's semantics can determine the morphosyntactic realization of its arguments. Assuming a close connection between verb meaning and syntactic structure, it provides a bridge between lexical-semantic and syntactic research, synthesizing the results of work from a range of linguistic subdisciplines and in a variety of theoretical frameworks. The first four chapters survey leading theories about event structure and conceptualization. The fifth and sixth chapters focus on the mapping from lexical semantics to morphosyntax and include a detailed discussion of the thematic hierarchy. The final chapter reviews treatments of multiple argument realization. With useful bibliographic references and clear definitions of relevant terms, this book will be invaluable to students and researchers in syntax and semantics, as well as those in related fields.},
  isbn = {978-0-521-66331-1},
  file = {/Users/siyu/Zotero/storage/2UNV89W6/Levin and Rappaport Hovav - 2005 - Argument Realization.pdf;/Users/siyu/Zotero/storage/D4SGSSN4/8B1F52537D0D9EF4EB63B6AE30DDB6DE.html}
}

@article{levin2015,
  title = {Semantics and {{Pragmatics}} of {{Argument Alternations}}},
  author = {Levin, Beth},
  date = {2015},
  journaltitle = {Annual Review of Linguistics},
  volume = {1},
  number = {1},
  pages = {63--83},
  doi = {10.1146/annurev-linguist-030514-125141},
  url = {https://doi.org/10.1146/annurev-linguist-030514-125141},
  urldate = {2019-09-12},
  abstract = {After setting out the challenges posed by argument alternations for linguistic theory, this article reviews the development of accounts of argument alternations over the past 50 years, documenting a shift from accounts that are primarily syntactic in nature to accounts with semantic and pragmatic components. The remainder of this review consists of case studies of the developing understanding of the semantics and pragmatics of the dative alternation and the causative alternation. Each case study stresses the interplay of semantic and contextual factors in characterizing the relation between the two variants that make up the alternation and in determining the choice of variant in a given context.},
  file = {/Users/siyu/Zotero/storage/ZSX7VEIT/Levin - 2015 - Semantics and Pragmatics of Argument Alternations.pdf}
}

@inbook{levin2015a,
  title = {Verb Classes within and across Languages},
  booktitle = {Valency Classes in the {{World}}'s Languages: {{Volume}} 2, {{Case}} Studies from {{Austronesia}} and the {{Pacific}}, the {{Americas}}, and Theoretical Outlook},
  author = {Levin, Beth},
  date = {2015},
  volume = {2},
  pages = {1627--1670},
  publisher = {{De Gruyter Mouton}},
  location = {{Berlin; Boston}},
  bookauthor = {Malchukov, Andrej and Comrie, Bernard},
  isbn = {978-3-11-043844-4},
  langid = {english},
  volumes = {2},
  annotation = {OCLC: 1015602777}
}

@inproceedings{levshina2020,
  title = {How Tight Is Your Language? {{A}} Semantic Typology Based on {{Mutual Information}}},
  shorttitle = {How Tight Is Your Language?},
  booktitle = {Proceedings of the 19th {{International Workshop}} on {{Treebanks}} and {{Linguistic Theories}}},
  author = {Levshina, Natalia},
  date = {2020},
  pages = {70--78},
  publisher = {{Association for Computational Linguistics}},
  location = {{Düsseldorf, Germany}},
  doi = {10.18653/v1/2020.tlt-1.7},
  url = {https://www.aclweb.org/anthology/2020.tlt-1.7},
  urldate = {2021-11-01},
  abstract = {Languages differ in the degree of semantic flexibility of their syntactic roles. For example, English and Indonesian are considered more flexible with regard to the semantics of subjects, whereas German and Japanese are less flexible. In Hawkins’ classification, more flexible languages are said to have a loose fit, and less flexible ones are those that have a tight fit. This classification has been based on manual inspection of example sentences. The present paper proposes a new, quantitative approach to deriving the measures of looseness and tightness from corpora. We use corpora of online news from the Leipzig Corpora Collection in thirty typologically and genealogically diverse languages and parse them syntactically with the help of the Universal Dependencies annotation software. Next, we compute Mutual Information scores for each language using the matrices of lexical lemmas and four syntactic dependencies (intransitive subjects, transitive subject, objects and obliques). The new approach allows us not only to reproduce the results of previous investigations, but also to extend the typology to new languages. We also demonstrate that verb-final languages tend to have a tighter relationship between lexemes and syntactic roles, which helps language users to recognize thematic roles early during comprehension.},
  eventtitle = {Proceedings of the 19th {{International Workshop}} on {{Treebanks}} and {{Linguistic Theories}}},
  langid = {english},
  file = {/Users/siyu/Zotero/storage/RD9UPA8Z/Levshina - 2020 - How tight is your language A semantic typology ba.pdf}
}

@article{levshina2022,
  title = {Frequency, {{Informativity}} and {{Word Length}}: {{Insights}} from {{Typologically Diverse Corpora}}},
  shorttitle = {Frequency, {{Informativity}} and {{Word Length}}},
  author = {Levshina, Natalia},
  date = {2022-02},
  journaltitle = {Entropy},
  volume = {24},
  number = {2},
  pages = {280},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  issn = {1099-4300},
  doi = {10.3390/e24020280},
  url = {https://www.mdpi.com/1099-4300/24/2/280},
  urldate = {2022-07-26},
  abstract = {Zipf’s law of abbreviation, which posits a negative correlation between word frequency and length, is one of the most famous and robust cross-linguistic generalizations. At the same time, it has been shown that contextual informativity (average surprisal given previous context) is more strongly correlated with word length, although this tendency is not observed consistently, depending on several methodological choices. The present study examines a more diverse sample of languages than the previous studies (Arabic, Finnish, Hungarian, Indonesian, Russian, Spanish and Turkish). I use large web-based corpora from the Leipzig Corpora Collection to estimate word lengths in UTF-8 characters and in phonemes (for some of the languages), as well as word frequency, informativity given previous word and informativity given next word, applying different methods of bigrams processing. The results show different correlations between word length and the corpus-based measure for different languages. I argue that these differences can be explained by the properties of noun phrases in a language, most importantly, by the order of heads and modifiers and their relative morphological complexity, as well as by orthographic conventions.},
  issue = {2},
  langid = {english},
  keywords = {corpora,frequency,informativity,linguistic typology,n-grams,Zipf’s law of abbreviation},
  file = {/Users/siyu/Zotero/storage/3LWBTX95/Levshina - 2022 - Frequency, Informativity and Word Length Insights.pdf;/Users/siyu/Zotero/storage/VGAZNS3V/280.html}
}

@incollection{luraghi2021,
  title = {Valency and Transitivity over Time: {{An}} Introduction},
  shorttitle = {Valency and Transitivity over Time},
  booktitle = {Valency over {{Time}}},
  author = {Luraghi, Silvia and Roma, Elisa},
  date = {2021-10-25},
  pages = {1--12},
  publisher = {{De Gruyter Mouton}},
  doi = {10.1515/9783110755657-001},
  url = {https://www.degruyter.com/document/doi/10.1515/9783110755657-001/html},
  urldate = {2022-06-20},
  isbn = {978-3-11-075565-7},
  langid = {english},
  file = {/Users/siyu/Zotero/storage/2ANWBLEG/Luraghi and Roma - 2021 - Valency and transitivity over time An introductio.pdf}
}

@book{malchukov2010,
  title = {Studies in {{Ditransitive Constructions}}: {{A Comparative Handbook}}},
  shorttitle = {Studies in {{Ditransitive Constructions}}},
  editor = {Malchukov, Andrej and Haspelmath, Martin and Comrie, Bernard},
  date = {2010-12-23},
  journaltitle = {Studies in Ditransitive Constructions},
  publisher = {{De Gruyter Mouton}},
  doi = {10.1515/9783110220377},
  url = {https://www.degruyter.com/document/doi/10.1515/9783110220377/html?lang=en},
  urldate = {2022-11-16},
  abstract = {This rich volume deals comprehensively with cross-linguistic variation in the morphosyntax of ditransitive constructions: constructions formed with verbs (like give) that take Agent, Theme and Recipient arguments. For the first time, a broadly cross-linguistic perspective is adopted. The present volume, consisting of an overview article and twenty-odd in-depth studies of ditransitive constructions in individual languages from different continents, arose from the conference on ditransitive constructions held at the Max Planck Institute for Evolutionary Anthropology (Leipzig) in 2007. It opens with the editors' survey article providing an overview of cross-linguistic variation in ditransitive constructions, followed by the questionnaire on ditransitive constructions, compiled by the editors in order to elicit various properties of these patterns. The editors' overview discusses formal properties of ditransitive constructions as well as behavioral (or syntactic) and lexical properties (i.e., the extension of ditransitive constructions across different verb classes). The volume includes 23 contributions describing properties of ditransitive constructions in languages from all over the world, written by leading experts. Care has been taken that the contributions to the volume will be representative of structural, geographic and genealogical diversity in the domain of ditransitive constructions. Thus the present volume provides a unique source of information on typological diversity of ditransitive constructions. It is expected that it will be of central interest to all scholars and advanced students of linguistics, especially to those working in the field of language typology and comparative syntax.},
  isbn = {978-3-11-022037-7},
  langid = {english},
  keywords = {Functional Grammar,Language Typology,Syntax},
  file = {/Users/siyu/Zotero/storage/W7TYKAZQ/2010 - Studies in Ditransitive Constructions A Comparati.pdf}
}

@mvbook{malchukov2015,
  title = {Valency Classes in the {{World}}'s Languages: {{Volume}} 2, {{Case}} Studies from {{Austronesia}} and the {{Pacific}}, the {{Americas}}, and Theoretical Outlook},
  author = {Malchukov, Andrej and Comrie, Bernard},
  date = {2015},
  volume = {2},
  publisher = {{De Gruyter Mouton}},
  location = {{Berlin; Boston}},
  isbn = {978-3-11-043844-4},
  langid = {english},
  volumes = {2},
  annotation = {OCLC: 1015602777},
  file = {/Users/siyu/Zotero/storage/MZ4RHGYQ/Malchukov and Comrie - 2015 - Valency classes in the World's languages Volume 2.pdf}
}

@mvbook{malchukov2015a,
  title = {Valency Classes in the {{World}}'s Languages: {{Volume}} 1 {{Introducing}} the Framework, and Case Studies from {{Africa}} and {{Eurasia}}},
  author = {Malchukov, Andrej and Comrie, Bernard},
  date = {2015},
  volume = {1},
  publisher = {{De Gruyter Mouton}},
  location = {{Berlin; Boston}},
  isbn = {978-3-11-033294-0},
  langid = {english},
  volumes = {2},
  annotation = {OCLC: 1015602777},
  file = {/Users/siyu/Zotero/storage/6MHHTYFY/Malchukov and Comrie - 2015 - Valency classes in the World's languages Volume 1.pdf}
}

@inbook{malchukov2015b,
  title = {Valency Classes and Alternations: Parameters of Variation},
  booktitle = {Valency Classes in the {{World}}'s Languages: {{Volume}} 1 {{Introducing}} the Framework, and Case Studies from {{Africa}} and {{Eurasia}}},
  author = {Malchukov, Andrej},
  date = {2015},
  volume = {1},
  pages = {73--130},
  publisher = {{De Gruyter Mouton}},
  location = {{Berlin; Boston}},
  bookauthor = {Malchukov, Andrej and Comrie, Bernard},
  isbn = {978-3-11-033294-0},
  langid = {english},
  volumes = {2},
  annotation = {OCLC: 1015602777}
}

@article{manning2020,
  title = {Emergent Linguistic Structure in Artificial Neural Networks Trained by Self-Supervision},
  author = {Manning, Christopher D. and Clark, Kevin and Hewitt, John and Khandelwal, Urvashi and Levy, Omer},
  date = {2020-12-01},
  journaltitle = {Proceedings of the National Academy of Sciences},
  shortjournal = {PNAS},
  volume = {117},
  number = {48},
  eprint = {32493748},
  eprinttype = {pmid},
  pages = {30046--30054},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1907367117},
  url = {https://www.pnas.org/content/117/48/30046},
  urldate = {2021-11-17},
  abstract = {This paper explores the knowledge of linguistic structure learned by large artificial neural networks, trained via self-supervision, whereby the model simply tries to predict a masked word in a given context. Human language communication is via sequences of words, but language understanding requires constructing rich hierarchical structures that are never observed explicitly. The mechanisms for this have been a prime mystery of human language acquisition, while engineering work has mainly proceeded by supervised learning on treebanks of sentences hand labeled for this latent structure. However, we demonstrate that modern deep contextual language models learn major aspects of this structure, without any explicit supervision. We develop methods for identifying linguistic hierarchical structure emergent in artificial neural networks and demonstrate that components in these models focus on syntactic grammatical relationships and anaphoric coreference. Indeed, we show that a linear transformation of learned embeddings in these models captures parse tree distances to a surprising degree, allowing approximate reconstruction of the sentence tree structures normally assumed by linguists. These results help explain why these models have brought such large improvements across many language-understanding tasks.},
  langid = {english},
  keywords = {artificial neural netwok,learning,self-supervision,syntax},
  file = {/Users/siyu/Zotero/storage/FZLWHUID/Manning et al. - 2020 - Emergent linguistic structure in artificial neural.pdf;/Users/siyu/Zotero/storage/GKFNKDH7/30046.html}
}

@inproceedings{mccarthy2020,
  title = {Measuring the {{Similarity}} of {{Grammatical Gender Systems}} by {{Comparing Partitions}}},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {McCarthy, Arya D. and Williams, Adina and Liu, Shijia and Yarowsky, David and Cotterell, Ryan},
  date = {2020-11},
  pages = {5664--5675},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online}},
  doi = {10.18653/v1/2020.emnlp-main.456},
  url = {https://aclanthology.org/2020.emnlp-main.456},
  urldate = {2022-06-06},
  abstract = {A grammatical gender system divides a lexicon into a small number of relatively fixed grammatical categories. How similar are these gender systems across languages? To quantify the similarity, we define gender systems extensionally, thereby reducing the problem of comparisons between languages' gender systems to cluster evaluation. We borrow a rich inventory of statistical tools for cluster evaluation from the field of community detection (Driver and Kroeber, 1932; Cattell, 1945), that enable us to craft novel information theoretic metrics for measuring similarity between gender systems. We first validate our metrics, then use them to measure gender system similarity in 20 languages. We then ask whether our gender system similarities alone are sufficient to reconstruct historical relationships between languages. Towards this end, we make phylogenetic predictions on the popular, but thorny, problem from historical linguistics of inducing a phylogenetic tree over extant Indo-European languages. Of particular interest, languages on the same branch of our phylogenetic tree are notably similar, whereas languages from separate branches are no more similar than chance.},
  eventtitle = {{{EMNLP}} 2020},
  file = {/Users/siyu/Zotero/storage/VAIQVBIP/McCarthy et al. - 2020 - Measuring the Similarity of Grammatical Gender Sys.pdf}
}

@inproceedings{meister2021,
  title = {Revisiting the {{Uniform Information Density Hypothesis}}},
  booktitle = {Proceedings of the 2021 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Meister, Clara and Pimentel, Tiago and Haller, Patrick and Jäger, Lena and Cotterell, Ryan and Levy, Roger},
  date = {2021-11},
  pages = {963--980},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online and Punta Cana, Dominican Republic}},
  doi = {10.18653/v1/2021.emnlp-main.74},
  url = {https://aclanthology.org/2021.emnlp-main.74},
  urldate = {2022-07-12},
  abstract = {The uniform information density (UID) hypothesis posits a preference among language users for utterances structured such that information is distributed uniformly across a signal. While its implications on language production have been well explored, the hypothesis potentially makes predictions about language comprehension and linguistic acceptability as well. Further, it is unclear how uniformity in a linguistic signal—or lack thereof—should be measured, and over which linguistic unit, e.g., the sentence or language level, this uniformity should hold. Here we investigate these facets of the UID hypothesis using reading time and acceptability data. While our reading time results are generally consistent with previous work, they are also consistent with a weakly super-linear effect of surprisal, which would be compatible with UID's predictions. For acceptability judgments, we find clearer evidence that non-uniformity in information density is predictive of lower acceptability. We then explore multiple operationalizations of UID, motivated by different interpretations of the original hypothesis, and analyze the scope over which the pressure towards uniformity is exerted. The explanatory power of a subset of the proposed operationalizations suggests that the strongest trend may be a regression towards a mean surprisal across the language, rather than the phrase, sentence, or document—a finding that supports a typical interpretation of UID, namely that it is the byproduct of language users maximizing the use of a (hypothetical) communication channel.},
  eventtitle = {{{EMNLP}} 2021},
  file = {/Users/siyu/Zotero/storage/ISDQ6NZ9/Meister et al. - 2021 - Revisiting the Uniform Information Density Hypothe.pdf}
}

@article{mollica2021,
  title = {The Forms and Meanings of Grammatical Markers Support Efficient Communication},
  author = {Mollica, Francis and Bacon, Geoff and Zaslavsky, Noga and Xu, Yang and Regier, Terry and Kemp, Charles},
  date = {2021-12-07},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {118},
  number = {49},
  pages = {e2025993118},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.2025993118},
  url = {https://www.pnas.org/doi/full/10.1073/pnas.2025993118},
  urldate = {2022-07-12},
  file = {/Users/siyu/Zotero/storage/UTI489ST/Mollica et al. - 2021 - The forms and meanings of grammatical markers supp.pdf}
}

@article{moore2015,
  title = {Semantic Typology: {{New}} Approaches to Crosslinguistic Variation in Language and Cognition},
  shorttitle = {Semantic Typology},
  author = {Moore, Randi and Donelson, Katharine and Eggleston, Alyson and Bohnemeyer, Juergen},
  date = {2015-12-01},
  journaltitle = {Linguistics Vanguard},
  volume = {1},
  number = {1},
  pages = {189--200},
  publisher = {{De Gruyter Mouton}},
  issn = {2199-174X},
  doi = {10.1515/lingvan-2015-1004},
  url = {https://www.degruyter.com/document/doi/10.1515/lingvan-2015-1004/html},
  urldate = {2021-11-11},
  abstract = {This article presents an overview of the goals and methods of semantic typology, the study of the distribution of semantic categories across languages. Results from this field inform theoretical accounts of syntax-semantics interface phenomena, as well as the nature of the relationship between language and cognition. This article discusses a variety of quantitative methods that represent recent efforts in semantic typology to (i) discover patterns in the distribution of independent variables and (ii) predict the distribution of dependent variables in relation to identified independent variables. Such methods include Multi-Dimensional Scaling, Hierarchical Cluster Analysis, and Generalized Linear Mixed Effects regression analyses. We identify and discuss notable published examples of these methods used in semantic typology.},
  langid = {english},
  keywords = {multivariate analyses,quantitative methods,semantic typology},
  file = {/Users/siyu/Zotero/storage/6Q68A397/Moore et al. - 2015 - Semantic typology New approaches to crosslinguist.pdf}
}

@book{nichols1999,
  title = {Linguistic Diversity in Space and Time},
  author = {Nichols, Johanna},
  date = {1999},
  publisher = {{University of Chicago Press}},
  location = {{Chicago}},
  isbn = {978-0-226-58057-9},
  langid = {english},
  annotation = {OCLC: 1120449452},
  file = {/Users/siyu/Zotero/storage/Y2PP2L8K/Nichols - 1999 - Linguistic diversity in space and time.pdf}
}

@inproceedings{nivre2020,
  title = {Universal {{Dependencies}} v2: {{An Evergrowing Multilingual Treebank Collection}}},
  shorttitle = {Universal {{Dependencies}} V2},
  booktitle = {Proceedings of the 12th {{Language Resources}} and {{Evaluation Conference}}},
  author = {Nivre, Joakim and de Marneffe, Marie-Catherine and Ginter, Filip and Hajič, Jan and Manning, Christopher D. and Pyysalo, Sampo and Schuster, Sebastian and Tyers, Francis and Zeman, Daniel},
  options = {useprefix=true},
  date = {2020-05},
  pages = {4034--4043},
  publisher = {{European Language Resources Association}},
  location = {{Marseille, France}},
  url = {https://aclanthology.org/2020.lrec-1.497},
  urldate = {2022-08-22},
  abstract = {Universal Dependencies is an open community effort to create cross-linguistically consistent treebank annotation for many languages within a dependency-based lexicalist framework. The annotation consists in a linguistically motivated word segmentation; a morphological layer comprising lemmas, universal part-of-speech tags, and standardized morphological features; and a syntactic layer focusing on syntactic relations between predicates, arguments and modifiers. In this paper, we describe version 2 of the universal guidelines (UD v2), discuss the major changes from UD v1 to UD v2, and give an overview of the currently available treebanks for 90 languages.},
  eventtitle = {{{LREC}} 2020},
  isbn = {979-10-95546-34-4},
  langid = {english},
  file = {/Users/siyu/Zotero/storage/TZBC45VP/Nivre et al. - 2020 - Universal Dependencies v2 An Evergrowing Multilin.pdf}
}

@inproceedings{oncevay2020,
  title = {Bridging {{Linguistic Typology}} and {{Multilingual Machine Translation}} with {{Multi-View Language Representations}}},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Oncevay, Arturo and Haddow, Barry and Birch, Alexandra},
  date = {2020},
  pages = {2391--2406},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online}},
  doi = {10.18653/v1/2020.emnlp-main.187},
  url = {https://www.aclweb.org/anthology/2020.emnlp-main.187},
  urldate = {2021-11-01},
  abstract = {Sparse language vectors from linguistic typology databases and learned embeddings from tasks like multilingual machine translation have been investigated in isolation, without analysing how they could benefit from each other’s language characterisation. We propose to fuse both views using singular vector canonical correlation analysis and study what kind of information is induced from each source. By inferring typological features and language phylogenies, we observe that our representations embed typology and strengthen correlations with language relationships. We then take advantage of our multi-view language vector space for multilingual machine translation, where we achieve competitive overall translation accuracy in tasks that require information about language similarities, such as language clustering and ranking candidates for multilingual transfer. With our method, which is also released as a tool, we can easily project and assess new languages without expensive retraining of massive multilingual or ranking models, which are major disadvantages of related approaches.},
  eventtitle = {Proceedings of the 2020 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  langid = {english},
  file = {/Users/siyu/Zotero/storage/HG5MMBYJ/Oncevay et al. - 2020 - Bridging Linguistic Typology and Multilingual Mach.pdf}
}

@article{palmer2005,
  title = {The {{Proposition Bank}}: {{An Annotated Corpus}} of {{Semantic Roles}}},
  shorttitle = {The {{Proposition Bank}}},
  author = {Palmer, Martha and Gildea, Daniel and Kingsbury, Paul},
  date = {2005},
  journaltitle = {Computational Linguistics},
  volume = {31},
  number = {1},
  pages = {71--106},
  doi = {10.1162/0891201053630264},
  url = {https://www.aclweb.org/anthology/J05-1004},
  urldate = {2019-09-18},
  file = {/Users/siyu/Zotero/storage/VB6JY5QJ/Palmer et al. - 2005 - The Proposition Bank An Annotated Corpus of Seman.pdf}
}

@inproceedings{papadimitriou2022,
  title = {When Classifying Grammatical Role, {{BERT}} Doesn't Care about Word Order... except When It Matters},
  booktitle = {Proceedings of the 60th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 2: {{Short Papers}})},
  author = {Papadimitriou, Isabel and Futrell, Richard and Mahowald, Kyle},
  date = {2022-05},
  pages = {636--643},
  publisher = {{Association for Computational Linguistics}},
  location = {{Dublin, Ireland}},
  doi = {10.18653/v1/2022.acl-short.71},
  url = {https://aclanthology.org/2022.acl-short.71},
  urldate = {2022-06-06},
  abstract = {Because meaning can often be inferred from lexical semantics alone, word order is often a redundant cue in natural language. For example, the words chopped, chef, and onion are more likely used to convey “The chef chopped the onion,” not “The onion chopped the chef.” Recent work has shown large language models to be surprisingly word order invariant, but crucially has largely considered natural prototypical inputs, where compositional meaning mostly matches lexical expectations. To overcome this confound, we probe grammatical role representation in English BERT and GPT-2, on instances where lexical expectations are not sufficient, and word order knowledge is necessary for correct classification. Such non-prototypical instances are naturally occurring English sentences with inanimate subjects or animate objects, or sentences where we systematically swap the arguments to make sentences like “The onion chopped the chef”. We find that, while early layer embeddings are largely lexical, word order is in fact crucial in defining the later-layer representations of words in semantically non-prototypical positions. Our experiments isolate the effect of word order on the contextualization process, and highlight how models use context in the uncommon, but critical, instances where it matters.},
  eventtitle = {{{ACL}} 2022},
  file = {/Users/siyu/Zotero/storage/ZSUA9A6Q/Papadimitriou et al. - 2022 - When classifying grammatical role, BERT doesn't ca.pdf}
}

@article{peirce1897,
  title = {The {{Logic}} of {{Relatives}}},
  author = {Peirce, Charles S.},
  date = {1897},
  journaltitle = {The Monist},
  volume = {7},
  number = {2},
  eprint = {27897407},
  eprinttype = {jstor},
  pages = {161--217},
  publisher = {{Oxford University Press}},
  issn = {0026-9662},
  file = {/Users/siyu/Zotero/storage/I89NHC5Z/Peirce - 1897 - THE LOGIC OF RELATIVES.pdf}
}

@article{piantadosi2011,
  title = {Word Lengths Are Optimized for Efficient Communication},
  author = {Piantadosi, Steven T. and Tily, Harry and Gibson, Edward},
  date = {2011-03},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {108},
  number = {9},
  pages = {3526--3529},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.1012551108},
  url = {https://www.pnas.org/doi/full/10.1073/pnas.1012551108},
  urldate = {2022-07-12},
  file = {/Users/siyu/Zotero/storage/ADEP9UXC/Piantadosi et al. - 2011 - Word lengths are optimized for efficient communica.pdf}
}

@inproceedings{pimentel2020,
  title = {Speakers {{Fill Lexical Semantic Gaps}} with {{Context}}},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Pimentel, Tiago and Hall Maudslay, Rowan and Blasi, Damián and Cotterell, Ryan},
  date = {2020-11},
  pages = {4004--4015},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online}},
  doi = {10.18653/v1/2020.emnlp-main.328},
  url = {https://aclanthology.org/2020.emnlp-main.328},
  urldate = {2022-07-12},
  abstract = {Lexical ambiguity is widespread in language, allowing for the reuse of economical word forms and therefore making language more efficient. If ambiguous words cannot be disambiguated from context, however, this gain in efficiency might make language less clear—resulting in frequent miscommunication. For a language to be clear and efficiently encoded, we posit that the lexical ambiguity of a word type should correlate with how much information context provides about it, on average. To investigate whether this is the case, we operationalise the lexical ambiguity of a word as the entropy of meanings it can take, and provide two ways to estimate this—one which requires human annotation (using WordNet), and one which does not (using BERT), making it readily applicable to a large number of languages. We validate these measures by showing that, on six high-resource languages, there are significant Pearson correlations between our BERT-based estimate of ambiguity and the number of synonyms a word has in WordNet (e.g. \$\textbackslash rho = 0.40\$ in English). We then test our main hypothesis—that a word's lexical ambiguity should negatively correlate with its contextual uncertainty—and find significant correlations on all 18 typologically diverse languages we analyse. This suggests that, in the presence of ambiguity, speakers compensate by making contexts more informative.},
  eventtitle = {{{EMNLP}} 2020},
  file = {/Users/siyu/Zotero/storage/J9BPSPAT/Pimentel et al. - 2020 - Speakers Fill Lexical Semantic Gaps with Context.pdf}
}

@inproceedings{pimentel2021,
  title = {How ({{Non-}}){{Optimal}} Is the {{Lexicon}}?},
  booktitle = {Proceedings of the 2021 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}},
  author = {Pimentel, Tiago and Nikkarinen, Irene and Mahowald, Kyle and Cotterell, Ryan and Blasi, Damián},
  date = {2021-06},
  pages = {4426--4438},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online}},
  doi = {10.18653/v1/2021.naacl-main.350},
  url = {https://aclanthology.org/2021.naacl-main.350},
  urldate = {2022-07-12},
  abstract = {The mapping of lexical meanings to wordforms is a major feature of natural languages. While usage pressures might assign short words to frequent meanings (Zipf's law of abbreviation), the need for a productive and open-ended vocabulary, local constraints on sequences of symbols, and various other factors all shape the lexicons of the world's languages. Despite their importance in shaping lexical structure, the relative contributions of these factors have not been fully quantified. Taking a coding-theoretic view of the lexicon and making use of a novel generative statistical model, we define upper bounds for the compressibility of the lexicon under various constraints. Examining corpora from 7 typologically diverse languages, we use those upper bounds to quantify the lexicon's optimality and to explore the relative costs of major constraints on natural codes. We find that (compositional) morphology and graphotactics can sufficiently account for most of the complexity of natural codes—as measured by code length.},
  eventtitle = {{{NAACL-HLT}} 2021},
  file = {/Users/siyu/Zotero/storage/YQXUZZXG/Pimentel et al. - 2021 - How (Non-)Optimal is the Lexicon.pdf}
}

@inproceedings{pimentel2021a,
  title = {A {{Bayesian Framework}} for {{Information-Theoretic Probing}}},
  booktitle = {Proceedings of the 2021 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Pimentel, Tiago and Cotterell, Ryan},
  date = {2021-11},
  pages = {2869--2887},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online and Punta Cana, Dominican Republic}},
  doi = {10.18653/v1/2021.emnlp-main.229},
  url = {https://aclanthology.org/2021.emnlp-main.229},
  urldate = {2022-07-12},
  abstract = {Pimentel et al. (2020) recently analysed probing from an information-theoretic perspective. They argue that probing should be seen as approximating a mutual information. This led to the rather unintuitive conclusion that representations encode exactly the same information about a target task as the original sentences. The mutual information, however, assumes the true probability distribution of a pair of random variables is known, leading to unintuitive results in settings where it is not. This paper proposes a new framework to measure what we term Bayesian mutual information, which analyses information from the perspective of Bayesian agents—allowing for more intuitive findings in scenarios with finite data. For instance, under Bayesian MI we have that data can add information, processing can help, and information can hurt, which makes it more intuitive for machine learning applications. Finally, we apply our framework to probing where we believe Bayesian mutual information naturally operationalises ease of extraction by explicitly limiting the available background knowledge to solve a task.},
  eventtitle = {{{EMNLP}} 2021},
  file = {/Users/siyu/Zotero/storage/JLB7Z8VM/Pimentel and Cotterell - 2021 - A Bayesian Framework for Information-Theoretic Pro.pdf}
}

@inproceedings{poumay2021,
  title = {A {{Comprehensive Comparison}} of {{Word Embeddings}} in {{Event}} \& {{Entity Coreference Resolution}}.},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{EMNLP}} 2021},
  author = {Poumay, Judicael and Ittoo, Ashwin},
  date = {2021-11},
  pages = {2755--2764},
  publisher = {{Association for Computational Linguistics}},
  location = {{Punta Cana, Dominican Republic}},
  url = {https://aclanthology.org/2021.findings-emnlp.235},
  urldate = {2021-11-10},
  abstract = {Coreference Resolution is an important NLP task and most state-of-the-art methods rely on word embeddings for word representation. However, one issue that has been largely overlooked in literature is that of comparing the performance of different embeddings across and within families. Therefore, we frame our study in the context of Event and Entity Coreference Resolution (EvCR \& EnCR), and address two questions : 1) Is there a trade-off between performance (predictive and run-time) and embedding size? 2) How do the embeddings' performance compare within and across families? Our experiments reveal several interesting findings. First, we observe diminishing returns in performance with respect to embedding size. E.g. a model using solely a character embedding achieves 86\% of the performance of the largest model (Elmo, GloVe, Character) while being 1.2\% of its size. Second, the larger models using multiple embeddings learns faster despite being slower per epoch. However, it is still slower at test time. Finally, Elmo performs best on both EvCR and EnCR, while GloVe and FastText perform best in EvCR and EnCR respectively.},
  eventtitle = {{{EMNLP-Findings}} 2021},
  file = {/Users/siyu/Zotero/storage/N5G9X6EC/Poumay and Ittoo - 2021 - A Comprehensive Comparison of Word Embeddings in E.pdf}
}

@article{przepiorkowski2018,
  title = {The Origin of the Valency Metaphor in Linguistics},
  author = {Przepiórkowski, Adam},
  date = {2018-01-01},
  journaltitle = {Lingvisticæ Investigationes},
  volume = {41},
  number = {1},
  pages = {152--159},
  publisher = {{John Benjamins}},
  issn = {0378-4169, 1569-9927},
  doi = {10.1075/li.00017.prz},
  url = {https://www.jbe-platform.com/content/journals/10.1075/li.00017.prz},
  urldate = {2022-09-18},
  abstract = {The aim of this squib is to question the popular belief that the metaphor of valency was introduced to linguistics by Lucien Tesnière in the middle of 20th century. Rather, we show that it was first used by Charles Peirce half a century earlier, leading to apparently independent – but probably mediated by Roman Jakobson – ‘discoveries’ of this metaphor by linguists in the Soviet Union, Holland, USA and indeed France.},
  langid = {english},
  file = {/Users/siyu/Zotero/storage/SY4EFPT6/Przepiórkowski - 2018 - The origin of the valency metaphor in linguistics.pdf}
}

@inproceedings{quasthoff2020,
  title = {Typical {{Sentences}} as a {{Resource}} for {{Valence}}},
  booktitle = {Proceedings of the 12th {{Language Resources}} and {{Evaluation Conference}}},
  author = {Quasthoff, Uwe and Hellan, Lars and Körner, Erik and Eckart, Thomas and Goldhahn, Dirk and Beermann, Dorothee},
  date = {2020-05},
  pages = {5276--5281},
  publisher = {{European Language Resources Association}},
  location = {{Marseille, France}},
  url = {https://aclanthology.org/2020.lrec-1.649},
  urldate = {2022-09-25},
  abstract = {Verb valence information can be derived from corpora by using subcorpora of typical sentences that are constructed in a language independent manner based on frequent POS structures. The inspection of typical sentences with a fixed verb in a certain position can show the valence information directly. Using verb fingerprints, consisting of the most typical sentence patterns the verb appears in, we are able to identify standard valence patterns and compare them against a language's valence profile. With a very limited number of training data per language, valence information for other verbs can be derived as well. Based on the Norwegian valence patterns we are able to find comparative patterns in German where typical sentences are able to express the same situation in an equivalent way and can so construct verb valence pairs for a bilingual PolyVal dictionary. This contribution discusses this application with a focus on the Norwegian valence dictionary NorVal.},
  eventtitle = {{{LREC}} 2020},
  isbn = {979-10-95546-34-4},
  langid = {english},
  file = {/Users/siyu/Zotero/storage/XI4ZYVFL/Quasthoff et al. - 2020 - Typical Sentences as a Resource for Valence.pdf}
}

@unpublished{rabinovich2020,
  title = {The {{Typology}} of {{Polysemy}}: {{A Multilingual Distributional Framework}}},
  shorttitle = {The {{Typology}} of {{Polysemy}}},
  author = {Rabinovich, Ella and Xu, Yang and Stevenson, Suzanne},
  date = {2020-06-02},
  eprint = {2006.01966},
  eprinttype = {arxiv},
  primaryclass = {cs},
  url = {http://arxiv.org/abs/2006.01966},
  urldate = {2021-11-01},
  abstract = {Lexical semantic typology has identified important cross-linguistic generalizations about the variation and commonalities in polysemy patterns---how languages package up meanings into words. Recent computational research has enabled investigation of lexical semantics at a much larger scale, but little work has explored lexical typology across semantic domains, nor the factors that influence cross-linguistic similarities. We present a novel computational framework that quantifies semantic affinity, the cross-linguistic similarity of lexical semantics for a concept. Our approach defines a common multilingual semantic space that enables a direct comparison of the lexical expression of concepts across languages. We validate our framework against empirical findings on lexical semantic typology at both the concept and domain levels. Our results reveal an intricate interaction between semantic domains and extra-linguistic factors, beyond language phylogeny, that co-shape the typology of polysemy across languages.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {/Users/siyu/Zotero/storage/8BKEB6FE/Rabinovich et al. - 2020 - The Typology of Polysemy A Multilingual Distribut.pdf;/Users/siyu/Zotero/storage/EQYEXASX/2006.html}
}

@incollection{rappaporthovav1998,
  title = {Building Verb Meanings},
  booktitle = {The {{Projection}} of {{Arguments}}: {{Lexical}} and {{Compositional Factors}}},
  author = {Rappaport Hovav, Malka and Levin, Beth},
  editor = {Butt, Miriam and Geuder, Wilhelm},
  date = {1998},
  series = {{{CSLI Lecture Notes}}},
  pages = {97--134},
  isbn = {978-1-57586-110-4},
  file = {/Users/siyu/Zotero/storage/GFB8VEZB/Malka and Levin - 1998 - Building verb meanings.pdf}
}

@article{ruder2019,
  title = {A {{Survey}} of {{Cross-lingual Word Embedding Models}}},
  author = {Ruder, Sebastian and Vulić, Ivan and Søgaard, Anders},
  date = {2019-08-12},
  journaltitle = {Journal of Artificial Intelligence Research},
  volume = {65},
  pages = {569--631},
  issn = {1076-9757},
  doi = {10.1613/jair.1.11640},
  url = {https://www.jair.org/index.php/jair/article/view/11640},
  urldate = {2022-09-06},
  abstract = {Cross-lingual representations of words enable us to reason about word meaning in multilingual contexts and are a key facilitator of cross-lingual transfer when developing natural language processing models for low-resource languages. In this survey, we provide a comprehensive typology of cross-lingual word embedding models. We compare their data requirements and objective functions. The recurring theme of the survey is that many of the models presented in the literature optimize for the same objectives, and that seemingly different models are often equivalent, modulo optimization strategies, hyper-parameters, and such. We also discuss the different ways cross-lingual word embeddings are evaluated, as well as future challenges and research horizons.},
  langid = {english},
  keywords = {machine learning,machine translation,natural language},
  file = {/Users/siyu/Zotero/storage/9VMXGGSR/Ruder et al. - 2019 - A Survey of Cross-lingual Word Embedding Models.pdf}
}

@article{say2014,
  title = {Bivalent {{Verb Classes}} in the {{Languages}} of {{Europe}}: {{A Quantitative Typological Study}}},
  shorttitle = {Bivalent {{Verb Classes}} in the {{Languages}} of {{Europe}}},
  author = {Say, Sergey},
  date = {2014-01-01},
  journaltitle = {Language Dynamics and Change},
  volume = {4},
  number = {1},
  pages = {116--166},
  publisher = {{Brill}},
  issn = {2210-5832, 2210-5824},
  doi = {10.1163/22105832-00401003},
  url = {https://brill.com/view/journals/ldc/4/1/article-p116_4.xml},
  urldate = {2022-06-20},
  abstract = {The aims of this study are twofold: to propose methods for measuring (dis)similarities in the organization of valency class systems across languages, and to test them on a sample of European languages in order to reveal areal and genetic patterns. The data were gathered for 29 languages using a questionnaire containing 130 contextualized uses of bivalent predicates. The properties under study include (i) lexical range of transitives, (ii) lexical range of valency frames defined in terms of the “locus” of non-transitivity (whether A or P arguments are encoded by oblique devices), (iii) overall complexity of valency class systems, and (iv) lexical distribution of verbs among valency classes. In case of the simpler properties (i)–(iii), maps with quantified isoglosses and pairwise comparison of languages based on Hamming distance are used. For (iv) these methods are inapplicable (valency classes cannot be equated across languages), and I propose a distance metric based on entropy and pairwise mutual information between distributions. The distance matrices are analyzed using the NeighborNet algorithm as implemented in SplitsTree. I argue that more holistic properties of valency class systems are indicative of large areal effects: e.g., many western European languages (Germanic, Romance, Basque and some Balkan languages) are lexically “most transitive” in Europe. Low-level areal signal is clearly discernible in the data on more subtle aspects of the organization of valency classes. The findings imply that distributions of verbs into valency classes can develop quickly and are transferable in contact situations, despite drastic dissimilarities in argument-coding devices.},
  langid = {english},
  keywords = {areal linguistics,languages of Europe,quantitative typology,transitivity,valency classes},
  file = {/Users/siyu/Zotero/storage/EDH3E4YA/Say - 2014 - Bivalent Verb Classes in the Languages of Europe .pdf}
}

@inproceedings{sayeed2018,
  title = {Rollenwechsel-{{English}}: A Large-Scale Semantic Role Corpus},
  shorttitle = {Rollenwechsel-{{English}}},
  booktitle = {Proceedings of the {{Eleventh International Conference}} on {{Language Resources}} and {{Evaluation}} ({{LREC}} 2018)},
  author = {Sayeed, Asad and Shkadzko, Pavel and Demberg, Vera},
  date = {2018-05},
  publisher = {{European Language Resources Association (ELRA)}},
  location = {{Miyazaki, Japan}},
  url = {https://aclanthology.org/L18-1488},
  urldate = {2022-06-07},
  eventtitle = {{{LREC}} 2018},
  file = {/Users/siyu/Zotero/storage/FG9ADJVT/Sayeed et al. - 2018 - Rollenwechsel-English a large-scale semantic role.pdf}
}

@inproceedings{schulteimwalde2002,
  title = {Inducing {{German Semantic Verb Classes}} from {{Purely Syntactic Subcategorisation Information}}},
  booktitle = {Proceedings of the 40th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Schulte im Walde, Sabine and Brew, Chris},
  date = {2002-07},
  pages = {223--230},
  publisher = {{Association for Computational Linguistics}},
  location = {{Philadelphia, Pennsylvania, USA}},
  doi = {10.3115/1073083.1073121},
  url = {https://www.aclweb.org/anthology/P02-1029},
  urldate = {2019-09-18},
  eventtitle = {{{ACL}} 2002},
  file = {/Users/siyu/Zotero/storage/R7RMZ4VV/Schulte im Walde and Brew - 2002 - Inducing German Semantic Verb Classes from Purely .pdf}
}

@article{schulteimwalde2006,
  title = {Experiments on the {{Automatic Induction}} of {{German Semantic Verb Classes}}},
  author = {Schulte im Walde, Sabine},
  date = {2006},
  journaltitle = {Computational Linguistics},
  volume = {32},
  number = {2},
  pages = {159--194},
  doi = {10.1162/coli.2006.32.2.159},
  url = {https://aclanthology.org/J06-2001},
  urldate = {2022-11-16},
  file = {/Users/siyu/Zotero/storage/RZ9HLEE9/Schulte im Walde - 2006 - Experiments on the Automatic Induction of German S.pdf}
}

@book{suihkonen2012,
  title = {Argument Structure and Grammatical Relations: A Crosslinguistic Typology},
  shorttitle = {Argument Structure and Grammatical Relations},
  author = {Suihkonen, Pirkko and Comrie, Bernard and Solovyev, Valery},
  date = {2012},
  publisher = {{John Benjamins Pub. Co.}},
  location = {{Amsterdam}},
  isbn = {978-90-272-0593-3},
  langid = {english},
  annotation = {OCLC: 939736927},
  file = {/Users/siyu/Zotero/storage/N89FSUEB/Suihkonen - 2012 - Argument structure and grammatical relations a cr.pdf}
}

@book{tahmasebi2021,
  title = {Computational Approaches to Semantic Change},
  author = {Tahmasebi, Nina and Borin, Lars and Jatowt, Adam and Xu, Yang and Hengchen, Simon and Vylomova, Ekaterina and Haslam, Nick and Mahanty, Sampriti and Boons, Frank and Handl, Julia and Batista-Navarro, Riza and Petersson, Stellan and Sköldberg, Emma and Zhang, Zheng-sheng and Grewal, Karan and Uban, Ana-Sabina and Ciobanu, Alina Maria and Dinu, Liviu P. and Duan, Yijun and Yoshikawa, Masatoshi and Perrone, Valerio and Palma, Marco and Vatri, Alessandro and Smith, Jim Q. and McGillivray, Barbara and Schlechtweg, Dominik and Dubossarsky, Haim},
  date = {2021-02-26},
  journaltitle = {Language Science Press},
  publisher = {{Language Science Press}},
  doi = {10.5281/zenodo.5040241},
  url = {https://langsci-press.org/catalog/view/303/3026/2385-1},
  urldate = {2022-05-11},
  abstract = {Semantic change\&nbsp;— how the meanings of words change over time\&nbsp;— has preoccupied scholars since well before modern linguistics emerged in the late 19th and early 20th century, ushering in a new methodological turn in the study of language change. Compared to changes in sound and grammar, semantic change is the least\&nbsp; understood. Ever since, the study of semantic change has progressed steadily, accumulating a vast store of knowledge for over a century, encompassing many languages and language families. Historical linguists also early on realized the potential of computers as research tools, with papers at the very first international conferences in computational linguistics in the 1960s. Such computational studies still tended to be small-scale, method-oriented, and qualitative. However, recent years have witnessed a sea-change in this regard. Big-data empirical quantitative investigations are now coming to the forefront, enabled by enormous advances in storage capability and processing power. Diachronic corpora have grown beyond imagination, defying exploration by traditional manual qualitative methods, and language technology has become increasingly data-driven and semantics-oriented. These developments present a golden opportunity for the empirical study of semantic change over both long and short time spans. A major challenge presently is to integrate the hard-earned\&nbsp; knowledge and expertise of traditional historical linguistics with\&nbsp; cutting-edge methodology explored primarily in computational linguistics. The idea for the present volume came out of a concrete response to this challenge.\&nbsp; The 1st International Workshop on Computational Approaches to Historical Language Change (LChange'19), at ACL 2019, brought together scholars from both fields. This volume offers a survey of this exciting new direction in the study of semantic change, a discussion of the many remaining challenges that we face in pursuing it, and considerably updated and extended versions of a selection of the contributions to the LChange'19 workshop, addressing both more theoretical problems —\&nbsp; e.g., discovery of "laws of semantic change"\&nbsp;— and practical applications, such as information retrieval in longitudinal text archives.},
  isbn = {978-3-96110-312-6},
  langid = {english},
  file = {/Users/siyu/Zotero/storage/XNY2SRNL/Tahmasebi et al. - 2021 - Computational approaches to semantic change.pdf}
}

@article{talmy1991,
  title = {Path to {{Realization}}: {{A Typology}} of {{Event Conflation}}},
  shorttitle = {Path to {{Realization}}},
  author = {Talmy, Leonard},
  date = {1991-07-25},
  journaltitle = {Annual Meeting of the Berkeley Linguistics Society},
  volume = {17},
  number = {1},
  pages = {480--519},
  issn = {2377-1666},
  doi = {10.3765/bls.v17i0.1620},
  url = {https://journals.linguisticsociety.org/proceedings/index.php/BLS/article/view/1620},
  urldate = {2022-07-11},
  abstract = {Proceedings of the Seventeenth Annual Meeting of the Berkeley Linguistics Society: General Session and Parasession on The Grammar of Event Structure (1991), pp. 480-519},
  issue = {1},
  langid = {american},
  file = {/Users/siyu/Zotero/storage/7KS9U9XM/Talmy - 1991 - Path to Realization A Typology of Event Conflatio.pdf}
}

@article{tang2018,
  title = {A State-of-the-Art of Semantic Change Computation},
  author = {Tang, Xuri},
  date = {2018-09},
  journaltitle = {Natural Language Engineering},
  volume = {24},
  number = {5},
  pages = {649--676},
  publisher = {{Cambridge University Press}},
  issn = {1351-3249, 1469-8110},
  doi = {10.1017/S1351324918000220},
  url = {https://www.cambridge.org/core/journals/natural-language-engineering/article/abs/stateoftheart-of-semantic-change-computation/CCD69C7C2306B0E4D246B456E236EFAF},
  urldate = {2022-05-11},
  abstract = {This paper reviews the state-of-the-art of one emergent field in computational linguistics—semantic change computation. It summarizes the literature by proposing a framework that identifies five components in the field: diachronic corpus, diachronic word sense characterization, change modelling, evaluation and data visualization. Despite its potentials, the review shows that current studies are mainly focused on testifying hypotheses of semantic change from theoretical linguistics and that several core issues remain to be tackled: the need of diachronic corpora for languages other than English, the comparison and development of approaches to diachronic word sense characterization and change modelling, the need of comprehensive evaluation data and further exploration of data visualization techniques for hypothesis justification.},
  langid = {english},
  file = {/Users/siyu/Zotero/storage/48VPD26J/Tang - 2018 - A state-of-the-art of semantic change computation.pdf;/Users/siyu/Zotero/storage/N5HTYBFY/CCD69C7C2306B0E4D246B456E236EFAF.html}
}

@book{tesniere1959,
  title = {Éléments de syntaxe structurale},
  author = {Tesnière, Lucien},
  date = {1959},
  publisher = {{C. Klincksieck}},
  location = {{Paris}},
  langid = {french},
  annotation = {OCLC: 644984180}
}

@book{tesniere2015,
  title = {Elements of {{Structural Syntax}}},
  author = {Tesnière, Lucien},
  date = {2015},
  publisher = {{John Benjamins Publishing Company}},
  doi = {10.1075/z.185},
  url = {https://library.oapen.org/handle/20.500.12657/30722},
  urldate = {2022-08-22},
  abstract = {This volume is now finally available in English, sixty years after the death of its author, Lucien Tesnière. It has been translated from the French original into German, Spanish, Italian, and Russian, and now at long last into English as well. The volume contains a comprehensive approach to the syntax of natural languages, an approach that is foundational for an entire stream in the modern study of syntax and grammar. This stream is known today as dependency grammar (DG). Drawing examples from dozens of languages, many of which he was proficient in, Tesnière presents insightful analyses of numerous phenomena of syntax. Among the highlights are the concepts of valency and head-initial vs. head-final languages. These concepts are now taken for granted by most modern theories of syntax, even by phrase structure grammars, which represent, in a sense, the opposite sort of approach to syntax from what Tesnière was advocating.},
  isbn = {978-90-272-1212-2},
  langid = {english},
  keywords = {Actant,Adjective,Adverb,bic Book Industry Communication::C Language::CF linguistics::CFK Grammar,Infinitive,Latin,Linguistics,Noun,Preposition and postposition,syntax,syntax & morphology,theoretical linguistics,Verb},
  annotation = {Accepted: 2018-01-01 23:55:55},
  file = {/Users/siyu/Zotero/storage/38JTFNGS/Tesnière - 2015 - Elements of Structural Syntax.pdf}
}

@inproceedings{titov2012,
  title = {A {{Bayesian Approach}} to {{Unsupervised Semantic Role Induction}}},
  booktitle = {Proceedings of the 13th {{Conference}} of the {{European Chapter}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Titov, Ivan and Klementiev, Alexandre},
  date = {2012-04},
  pages = {12--22},
  publisher = {{Association for Computational Linguistics}},
  location = {{Avignon, France}},
  url = {https://aclanthology.org/E12-1003},
  urldate = {2022-09-18},
  eventtitle = {{{EACL}} 2012},
  file = {/Users/siyu/Zotero/storage/962YMJGH/Titov and Klementiev - 2012 - A Bayesian Approach to Unsupervised Semantic Role .pdf}
}

@article{tsunoda1981,
  title = {Split Case-Marking Patterns in Verb-Types and Tense/Aspect/Mood},
  author = {Tsunoda, Tasaku},
  date = {1981-01-01},
  volume = {19},
  number = {5-6},
  pages = {389--438},
  publisher = {{De Gruyter Mouton}},
  issn = {1613-396X},
  doi = {10.1515/ling.1981.19.5-6.389},
  url = {https://www.degruyter.com/document/doi/10.1515/ling.1981.19.5-6.389/html?lang=en},
  urldate = {2022-09-25},
  abstract = {Article Split case-marking patterns in verb-types and tense/aspect/mood was published on January 1, 1981 in the journal Linguistics (volume 19, issue 5-6).},
  langid = {english},
  file = {/Users/siyu/Zotero/storage/78A7DGWC/Tasaku - 1981 - Split case-marking patterns in verb-types and tens.pdf}
}

@article{tsunoda1985,
  title = {Remarks on {{Transitivity}}},
  author = {Tsunoda, Tasaku},
  date = {1985},
  journaltitle = {Journal of Linguistics},
  volume = {21},
  number = {2},
  eprint = {4175793},
  eprinttype = {jstor},
  pages = {385--396},
  publisher = {{Cambridge University Press}},
  issn = {0022-2267},
  file = {/Users/siyu/Zotero/storage/VMTCV3QV/Tsunoda - 1985 - Remarks on Transitivity.pdf}
}

@inbook{tsunoda2015,
  title = {The Hierarchy of Two-Place Predicates: Its Limitations and Uses},
  booktitle = {Valency Classes in the {{World}}'s Languages: {{Volume}} 2, {{Case}} Studies from {{Austronesia}} and the {{Pacific}}, the {{Americas}}, and Theoretical Outlook},
  author = {Tsunoda, Tasaku},
  date = {2015},
  volume = {2},
  pages = {1597--1626},
  publisher = {{De Gruyter Mouton}},
  location = {{Berlin; Boston}},
  bookauthor = {Malchukov, Andrej and Comrie, Bernard},
  isbn = {978-3-11-043844-4},
  langid = {english},
  volumes = {2},
  annotation = {OCLC: 1015602777}
}

@misc{universaldep,
  title = {Universal Dependencies 2.10},
  author = {Zeman, Daniel and Nivre, Joakim and Abrams, Mitchell and Ackermann, Elia and Aepli, Noëmi and Aghaei, Hamid and Agić, Željko and Ahmadi, Amir and Ahrenberg, Lars and Ajede, Chika Kennedy and Aleksandravičiūtė, Gabrielė and Alfina, Ika and Algom, Avner and Andersen, Erik and Antonsen, Lene and Aplonova, Katya and Aquino, Angelina and Aragon, Carolina and Aranes, Glyd and Aranzabe, Maria Jesus and Arıcan, Bilge Nas and Arnardóttir, órunn and Arutie, Gashaw and Arwidarasti, Jessica Naraiswari and Asahara, Masayuki and Aslan, Deniz Baran and Asmazoğlu, Cengiz and Ateyah, Luma and Atmaca, Furkan and Attia, Mohammed and Atutxa, Aitziber and Augustinus, Liesbeth and Badmaeva, Elena and Balasubramani, Keerthana and Ballesteros, Miguel and Banerjee, Esha and Bank, Sebastian and Barbu Mititelu, Verginica and Barkarson, Starkaður and Basile, Rodolfo and Basmov, Victoria and Batchelor, Colin and Bauer, John and Bedir, Seyyit Talha and Bengoetxea, Kepa and Ben Moshe, Yifat and Berk, Gözde and Berzak, Yevgeni and Bhat, Irshad Ahmad and Bhat, Riyaz Ahmad and Biagetti, Erica and Bick, Eckhard and Bielinskienė, Agnė and Bjarnadóttir, Kristín and Blokland, Rogier and Bobicev, Victoria and Boizou, Loïc and Borges Völker, Emanuel and Börstell, Carl and Bosco, Cristina and Bouma, Gosse and Bowman, Sam and Boyd, Adriane and Braggaar, Anouck and Brokaitė, Kristina and Burchardt, Aljoscha and Candito, Marie and Caron, Bernard and Caron, Gauthier and Cassidy, Lauren and Cavalcanti, Tatiana and Cebiroğlu Eryiğit, Gülşen and Cecchini, Flavio Massimiliano and Celano, Giuseppe G. A. and Čéplö, Slavomír and Cesur, Neslihan and Cetin, Savas and Çetinoğlu, Özlem and Chalub, Fabricio and Chauhan, Shweta and Chi, Ethan and Chika, Taishi and Cho, Yongseok and Choi, Jinho and Chun, Jayeol and Chung, Juyeon and Cignarella, Alessandra T. and Cinková, Silvie and Collomb, Aurélie and Çöltekin, Çağrı and Connor, Miriam and Corbetta, Daniela and Courtin, Marine and Cristescu, Mihaela and Daniel, Philemon and Davidson, Elizabeth and Dehouck, Mathieu and de Laurentiis, Martina and de Marneffe, Marie-Catherine and de Paiva, Valeria and Derin, Mehmet Oguz and de Souza, Elvis and Diaz de Ilarraza, Arantza and Dickerson, Carly and Dinakaramani, Arawinda and Di Nuovo, Elisa and Dione, Bamba and Dirix, Peter and Dobrovoljc, Kaja and Dozat, Timothy and Droganova, Kira and Dwivedi, Puneet and Eckhoff, Hanne and Eiche, Sandra and Eli, Marhaba and Elkahky, Ali and Ephrem, Binyam and Erina, Olga and Erjavec, Tomaž and Etienne, Aline and Evelyn, Wograine and Facundes, Sidney and Farkas, Richárd and Favero, Federica and Ferdaousi, Jannatul and Fernanda, Marília and Fernandez Alcalde, Hector and Foster, Jennifer and Freitas, Cláudia and Fujita, Kazunori and Gajdošová, Katarína and Galbraith, Daniel and Gamba, Federica and Garcia, Marcos and Gärdenfors, Moa and Garza, Sebastian and Gerardi, Fabrício Ferraz and Gerdes, Kim and Ginter, Filip and Godoy, Gustavo and Goenaga, Iakes and Gojenola, Koldo and Gökırmak, Memduh and Goldberg, Yoav and Gómez Guinovart, Xavier and González Saavedra, Berta and Griciūtė, Bernadeta and Grioni, Matias and Grobol, Loïc and Grūztis, Normunds and Guillaume, Bruno and Guillot-Barbance, Céline and Güngör, Tunga and Habash, Nizar and Hafsteinsson, Hinrik and Hajič, Jan and Hajič jr., Jan and Hämäläinen, Mika and Hà Mỹ, Linh and Han, Na-Rae and Hanifmuti, Muhammad Yudistira and Harada, Takahiro and Hardwick, Sam and Harris, Kim and Haug, Dag and Heinecke, Johannes and Hellwig, Oliver and Hennig, Felix and Hladká, Barbora and Hlaváčová, Jaroslava and Hociung, Florinel and Hohle, Petter and Hwang, Jena and Ikeda, Takumi and Ingason, Anton Karl and Ion, Radu and Irimia, Elena and Ishola, Ọlájídé and Ito, Kaoru and Jannat, Siratun and Jelínek, Tomáš and Jha, Apoorva and Johannsen, Anders and Jónsdóttir, Hildur and Jørgensen, Fredrik and Juutinen, Markus and K, Sarveswaran and Kaşıkara, Hüner and Kaasen, Andre and Kabaeva, Nadezhda and Kahane, Sylvain and Kanayama, Hiroshi and Kanerva, Jenna and Kara, Neslihan and Karahóǧa, Ritván and Katz, Boris and Kayadelen, Tolga and Kenney, Jessica and Kettnerová, Václava and Kirchner, Jesse and Klementieva, Elena and Klyachko, Elena and Köhn, Arne and Köksal, Abdullatif and Kopacewicz, Kamil and Korkiakangas, Timo and Köse, Mehmet and Kotsyba, Natalia and Kovalevskaitė, Jolanta and Krek, Simon and Krishnamurthy, Parameswari and Kübler, Sandra and Kuyrukçu, Oğuzhan and Kuzgun, Aslı and Kwak, Sookyoung and Laippala, Veronika and Lam, Lucia and Lambertino, Lorenzo and Lando, Tatiana and Larasati, Septina Dian and Lavrentiev, Alexei and Lee, John and Lê Hồng, Phương and Lenci, Alessandro and Lertpradit, Saran and Leung, Herman and Levina, Maria and Li, Cheuk Ying and Li, Josie and Li, Keying and Li, Yuan and Lim, KyungTae and Lima Padovani, Bruna and Lindén, Krister and Ljubešić, Nikola and Loginova, Olga and Lusito, Stefano and Luthfi, Andry and Luukko, Mikko and Lyashevskaya, Olga and Lynn, Teresa and Macketanz, Vivien and Mahamdi, Menel and Maillard, Jean and Makazhanov, Aibek and Mandl, Michael and Manning, Christopher and Manurung, Ruli and Marşan, Büşra and Mărănduc, Cătălina and Mareček, David and Marheinecke, Katrin and Markantonatou, Stella and Martínez Alonso, Héctor and Martín Rodríguez, Lorena and Martins, André and Mašek, Jan and Matsuda, Hiroshi and Matsumoto, Yuji and Mazzei, Alessandro and McDonald, Ryan and McGuinness, Sarah and Mendonça, Gustavo and Merzhevich, Tatiana and Miekka, Niko and Mischenkova, Karina and Misirpashayeva, Margarita and Missilä, Anna and Mititelu, Cătălin and Mitrofan, Maria and Miyao, Yusuke and Mojiri Foroushani, AmirHossein and Molnár, Judit and Moloodi, Amirsaeid and Montemagni, Simonetta and More, Amir and Moreno Romero, Laura and Moretti, Giovanni and Mori, Keiko Sophie and Mori, Shinsuke and Morioka, Tomohiko and Moro, Shigeki and Mortensen, Bjartur and Moskalevskyi, Bohdan and Muischnek, Kadri and Munro, Robert and Murawaki, Yugo and Müürisep, Kaili and Nainwani, Pinkey and Nakhlé, Mariam and Navarro Horñiacek, Juan Ignacio and Nedoluzhko, Anna and Nešpore-Bērzkalne, Gunta and Nevaci, Manuela and Nguyễn Thị, Lương and Nguyễn Thị Minh, Huyền and Nikaido, Yoshihiro and Nikolaev, Vitaly and Nitisaroj, Rattima and Nourian, Alireza and Nurmi, Hanna and Ojala, Stina and Ojha, Atul Kr. and Olúòkun, Adédayọ̀ and Omura, Mai and Onwuegbuzia, Emeka and Ordan, Noam and Osenova, Petya and Östling, Robert and Øvrelid, Lilja and Özateş, Şaziye Betül and Özçelik, Merve and Özgür, Arzucan and Öztürk Başaran, Balkız and Paccosi, Teresa and Palmero Aprosio, Alessio and Park, Hyunji Hayley and Partanen, Niko and Pascual, Elena and Passarotti, Marco and Patejuk, Agnieszka and Paulino-Passos, Guilherme and Pedonese, Giulia and Peljak-Łapińska, Angelika and Peng, Siyao and Perez, Cenel-Augusto and Perkova, Natalia and Perrier, Guy and Petrov, Slav and Petrova, Daria and Peverelli, Andrea and Phelan, Jason and Piitulainen, Jussi and Pirinen, Tommi A and Pitler, Emily and Plank, Barbara and Poibeau, Thierry and Ponomareva, Larisa and Popel, Martin and Pretkalniņa, Lauma and Prévost, Sophie and Prokopidis, Prokopis and Przepiórkowski, Adam and Puolakainen, Tiina and Pyysalo, Sampo and Qi, Peng and Rääbis, Andriela and Rademaker, Alexandre and Rahoman, Mizanur and Rama, Taraka and Ramasamy, Loganathan and Ramisch, Carlos and Rashel, Fam and Rasooli, Mohammad Sadegh and Ravishankar, Vinit and Real, Livy and Rebeja, Petru and Reddy, Siva and Regnault, Mathilde and Rehm, Georg and Riabov, Ivan and Rießler, Michael and Rimkutė, Erika and Rinaldi, Larissa and Rituma, Laura and Rizqiyah, Putri and Rocha, Luisa and Rögnvaldsson, Eiríkur and Romanenko, Mykhailo and Rosa, Rudolf and Roșca, Valentin and Rovati, Davide and Rozonoyer, Ben and Rudina, Olga and Rueter, Jack and Rúnarsson, Kristján and Sadde, Shoval and Safari, Pegah and Sagot, Benoît and Sahala, Aleksi and Saleh, Shadi and Salomoni, Alessio and Samardžić, Tanja and Samson, Stephanie and Sanguinetti, Manuela and Sanıyar, Ezgi and Särg, Dage and Saulte, Baiba and Sawanakunanon, Yanin and Saxena, Shefali and Scannell, Kevin and Scarlata, Salvatore and Schneider, Nathan and Schuster, Sebastian and Schwartz, Lane and Seddah, Djamé and Seeker, Wolfgang and Seraji, Mojgan and Shahzadi, Syeda and Shen, Mo and Shimada, Atsuko and Shirasu, Hiroyuki and Shishkina, Yana and Shohibussirri, Muh and Sichinava, Dmitry and Siewert, Janine and Sigurðsson, Einar Freyr and Silveira, Aline and Silveira, Natalia and Simi, Maria and Simionescu, Radu and Simkó, Katalin and Šimková, Mária and Simov, Kiril and Skachedubova, Maria and Smith, Aaron and Soares-Bastos, Isabela and Sourov, Shafi and Spadine, Carolyn and Sprugnoli, Rachele and Stamou, Vivian and Steingrímsson, Steinór and Stella, Antonio and Straka, Milan and Strickland, Emmett and Strnadová, Jana and Suhr, Alane and Sulestio, Yogi Lesmana and Sulubacak, Umut and Suzuki, Shingo and Swanson, Daniel and Szántó, Zsolt and Taguchi, Chihiro and Taji, Dima and Takahashi, Yuta and Tamburini, Fabio and Tan, Mary Ann C. and Tanaka, Takaaki and Tanaya, Dipta and Tavoni, Mirko and Tella, Samson and Tellier, Isabelle and Testori, Marinella and Thomas, Guillaume and Tonelli, Sara and Torga, Liisi and Toska, Marsida and Trosterud, Trond and Trukhina, Anna and Tsarfaty, Reut and Türk, Utku and Tyers, Francis and Uematsu, Sumire and Untilov, Roman and Urešová, Zdeňka and Uria, Larraitz and Uszkoreit, Hans and Utka, Andrius and Vagnoni, Elena and Vajjala, Sowmya and van der Goot, Rob and Vanhove, Martine and van Niekerk, Daniel and van Noord, Gertjan and Varga, Viktor and Vedenina, Uliana and Villemonte de la Clergerie, Eric and Vincze, Veronika and Vlasova, Natalia and Wakasa, Aya and Wallenberg, Joel C. and Wallin, Lars and Walsh, Abigail and Wang, Jing Xian and Washington, Jonathan North and Wendt, Maximilan and Widmer, Paul and Wigderson, Shira and Wijono, Sri Hartati and Williams, Seyi and Wirén, Mats and Wittern, Christian and Woldemariam, Tsegay and Wong, Tak-sum and Wróblewska, Alina and Yako, Mary and Yamashita, Kayo and Yamazaki, Naoki and Yan, Chunxiao and Yasuoka, Koichi and Yavrumyan, Marat M. and Yenice, Arife Betül and Yıldız, Olcay Taner and Yu, Zhuoran and Yuliawati, Arlisa and Žabokrtský, Zdeněk and Zahra, Shorouq and Zeldes, Amir and Zhou, He and Zhu, Hanzhi and Zhuravleva, Anna and Ziane, Rayan},
  options = {useprefix=true},
  date = {2022},
  url = {http://hdl.handle.net/11234/1-4758}
}

@book{valpal,
  title = {The Valency Patterns Leipzig Online Database},
  author = {Hartmann, Iren and Haspelmath, Martin and Taylor, Bradley},
  date = {2013},
  publisher = {{Max Planck Institute for Evolutionary Anthropology}},
  location = {{Leipzig}},
  url = {https://valpal.info/}
}

@article{vangysel2021,
  title = {Designing a {{Uniform Meaning Representation}} for {{Natural Language Processing}}},
  author = {Van Gysel, Jens E. L. and Vigus, Meagan and Chun, Jayeol and Lai, Kenneth and Moeller, Sarah and Yao, Jiarui and O’Gorman, Tim and Cowell, Andrew and Croft, William and Huang, Chu-Ren and Hajič, Jan and Martin, James H. and Oepen, Stephan and Palmer, Martha and Pustejovsky, James and Vallejos, Rosa and Xue, Nianwen},
  date = {2021-11-01},
  journaltitle = {KI - Künstliche Intelligenz},
  shortjournal = {Künstl Intell},
  volume = {35},
  number = {3},
  pages = {343--360},
  issn = {1610-1987},
  doi = {10.1007/s13218-021-00722-w},
  url = {https://doi.org/10.1007/s13218-021-00722-w},
  urldate = {2022-09-06},
  abstract = {In this paper we present Uniform Meaning Representation (UMR), a meaning representation designed to annotate the semantic content of a text. UMR is primarily based on Abstract Meaning Representation (AMR), an annotation framework initially designed for English, but also draws from other meaning representations. UMR extends AMR to other languages, particularly morphologically complex, low-resource languages. UMR also adds features to AMR that are critical to semantic interpretation and enhances AMR by proposing a companion document-level representation that captures linguistic phenomena such as coreference as well as temporal and modal dependencies that potentially go beyond sentence boundaries.},
  langid = {english},
  keywords = {Meaning representation,Natural language processing},
  file = {/Users/siyu/Zotero/storage/2BF4Q7SK/Van Gysel et al. - 2021 - Designing a Uniform Meaning Representation for Nat.pdf}
}

@inproceedings{voita2020,
  title = {Information-{{Theoretic Probing}} with {{Minimum Description Length}}},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Voita, Elena and Titov, Ivan},
  date = {2020-11},
  pages = {183--196},
  publisher = {{Association for Computational Linguistics}},
  location = {{Online}},
  doi = {10.18653/v1/2020.emnlp-main.14},
  url = {https://aclanthology.org/2020.emnlp-main.14},
  urldate = {2022-07-12},
  abstract = {To measure how well pretrained representations encode some linguistic property, it is common to use accuracy of a probe, i.e. a classifier trained to predict the property from the representations. Despite widespread adoption of probes, differences in their accuracy fail to adequately reflect differences in representations. For example, they do not substantially favour pretrained representations over randomly initialized ones. Analogously, their accuracy can be similar when probing for genuine linguistic labels and probing for random synthetic tasks. To see reasonable differences in accuracy with respect to these random baselines, previous work had to constrain either the amount of probe training data or its model size. Instead, we propose an alternative to the standard probes, information-theoretic probing with minimum description length (MDL). With MDL probing, training a probe to predict labels is recast as teaching it to effectively transmit the data. Therefore, the measure of interest changes from probe accuracy to the description length of labels given representations. In addition to probe quality, the description length evaluates “the amount of effort” needed to achieve the quality. This amount of effort characterizes either (i) size of a probing model, or (ii) the amount of data needed to achieve the high quality. We consider two methods for estimating MDL which can be easily implemented on top of the standard probing pipelines: variational coding and online coding. We show that these methods agree in results and are more informative and stable than the standard probes.},
  eventtitle = {{{EMNLP}} 2020},
  file = {/Users/siyu/Zotero/storage/S49X6KPR/Voita and Titov - 2020 - Information-Theoretic Probing with Minimum Descrip.pdf}
}

@inproceedings{watanabe2010,
  title = {A {{Structured Model}} for {{Joint Learning}} of {{Argument Roles}} and {{Predicate Senses}}},
  booktitle = {Proceedings of the {{ACL}} 2010 {{Conference Short Papers}}},
  author = {Watanabe, Yotaro and Asahara, Masayuki and Matsumoto, Yuji},
  date = {2010-07},
  pages = {98--102},
  publisher = {{Association for Computational Linguistics}},
  location = {{Uppsala, Sweden}},
  url = {https://aclanthology.org/P10-2018},
  urldate = {2022-09-25},
  eventtitle = {{{ACL}} 2010},
  file = {/Users/siyu/Zotero/storage/GC2GV5G6/Watanabe et al. - 2010 - A Structured Model for Joint Learning of Argument .pdf}
}

@inproceedings{wendlandt2018,
  title = {Factors {{Influencing}} the {{Surprising Instability}} of {{Word Embeddings}}},
  booktitle = {Proceedings of the 2018 {{Conference}} of the {{North American Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}}, {{Volume}} 1 ({{Long Papers}})},
  author = {Wendlandt, Laura and Kummerfeld, Jonathan K. and Mihalcea, Rada},
  date = {2018-06},
  pages = {2092--2102},
  publisher = {{Association for Computational Linguistics}},
  location = {{New Orleans, Louisiana}},
  doi = {10.18653/v1/N18-1190},
  url = {https://aclanthology.org/N18-1190},
  urldate = {2021-11-10},
  abstract = {Despite the recent popularity of word embedding methods, there is only a small body of work exploring the limitations of these representations. In this paper, we consider one aspect of embedding spaces, namely their stability. We show that even relatively high frequency words (100-200 occurrences) are often unstable. We provide empirical evidence for how various factors contribute to the stability of word embeddings, and we analyze the effects of stability on downstream tasks.},
  eventtitle = {{{NAACL-HLT}} 2018},
  file = {/Users/siyu/Zotero/storage/8CNZWGHY/Wendlandt et al. - 2018 - Factors Influencing the Surprising Instability of .pdf}
}

@inbook{wichmann2015,
  title = {Statistical Observations on Implicational (Verb) Hierarchies},
  booktitle = {Valency Classes in the {{World}}'s Languages: {{Volume}} 1 {{Introducing}} the Framework, and Case Studies from {{Africa}} and {{Eurasia}}},
  author = {Wichmann, Søren},
  date = {2015},
  volume = {1},
  pages = {155--182},
  publisher = {{De Gruyter Mouton}},
  location = {{Berlin; Boston}},
  bookauthor = {Malchukov, Andrej and Comrie, Bernard},
  isbn = {978-3-11-033294-0},
  langid = {english},
  volumes = {2},
  annotation = {OCLC: 1015602777}
}

@inproceedings{xu2015,
  title = {A {{Computational Evaluation}} of {{Two Laws}} of {{Semantic Change}}},
  booktitle = {Proceedings of the 37th {{Annual Meeting}} of the {{Cognitive Science Society}}},
  author = {Xu, Yang and Kemp, Charles},
  date = {2015},
  publisher = {{Cognitive Science Society}},
  location = {{Austin, TX}},
  url = {https://cogsci.mindmodeling.org/2015/papers/0463/},
  eventtitle = {{{CogSci}} 2015},
  isbn = {978-0-9911967-2-2},
  file = {/Users/siyu/Zotero/storage/9WI4SGQ2/Xu and Kemp - A Computational Evaluation of Two Laws of Semantic.pdf}
}

@book{yuan2010,
  title = {Han yu pei jia yu fa yan jiu = 汉语配价语法研究},
  author = {Yuan, Yulin},
  date = {2010},
  publisher = {{Shang wu yin shu guan}},
  location = {{Beijing}},
  isbn = {978-7-100-06688-4},
  langid = {Table of contents also in English},
  annotation = {OCLC: 635377451},
  file = {/Users/siyu/Zotero/storage/97RJMG2M/Yuan and Yuan - 2010 - Han yu pei jia yu fa yan jiu.pdf}
}

@article{zaslavsky2018,
  title = {Efficient Compression in Color Naming and Its Evolution},
  author = {Zaslavsky, Noga and Kemp, Charles and Regier, Terry and Tishby, Naftali},
  date = {2018-07-31},
  journaltitle = {Proceedings of the National Academy of Sciences},
  volume = {115},
  number = {31},
  pages = {7937--7942},
  publisher = {{Proceedings of the National Academy of Sciences}},
  doi = {10.1073/pnas.1800521115},
  url = {https://www.pnas.org/doi/full/10.1073/pnas.1800521115},
  urldate = {2022-07-12},
  file = {/Users/siyu/Zotero/storage/7RP5KJJF/Zaslavsky et al. - 2018 - Efficient compression in color naming and its evol.pdf}
}

@article{zaslavsky2021,
  title = {Let's Talk (Efficiently) about Us: {{Person}} Systems Achieve near-Optimal Compression},
  shorttitle = {Let's Talk (Efficiently) about Us},
  author = {Zaslavsky, Noga and Maldonado, Mora and Culbertson, Jennifer},
  date = {2021},
  journaltitle = {Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume = {43},
  number = {43},
  url = {https://escholarship.org/uc/item/2sj4t8m3},
  urldate = {2022-07-12},
  abstract = {Systems of personal pronouns (e.g.,`you' and `I') vary widely across languages, but at the same time not all possible systems are attested. Linguistic theories have generally accounted for this in terms of strong grammatical constraints, but recent experimental work challenges this view. Here, we take a novel approach to understanding personal pronoun systems by invoking a recent information-theoretic framework for semantic systems that predicts that languages efficiently compress meanings into forms. We find that a test set of cross-linguistically attested personal pronoun systems achieves near-optimal compression, supporting the hypothesis that efficient compression shapes semantic systems. Further, our best-fitting model includes an egocentric bias that favors a salient speaker representation, accounting for a well-known typological generalization of person systems (`Zwicky's Generalization') without the need for a hard grammatical constraint.},
  langid = {english},
  file = {/Users/siyu/Zotero/storage/2QE9BIQX/Zaslavsky et al. - 2021 - Let's talk (efficiently) about us Person systems .pdf}
}

@misc{zhao2020,
  title = {Gender {{Bias}} in {{Multilingual Embeddings}} and {{Cross-Lingual Transfer}}},
  author = {Zhao, Jieyu and Mukherjee, Subhabrata and Hosseini, Saghar and Chang, Kai-Wei and Awadallah, Ahmed Hassan},
  date = {2020-05-02},
  number = {arXiv:2005.00699},
  eprint = {2005.00699},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  url = {http://arxiv.org/abs/2005.00699},
  urldate = {2022-05-18},
  abstract = {Multilingual representations embed words from many languages into a single semantic space such that words with similar meanings are close to each other regardless of the language. These embeddings have been widely used in various settings, such as cross-lingual transfer, where a natural language processing (NLP) model trained on one language is deployed to another language. While the crosslingual transfer techniques are powerful, they carry gender bias from the source to target languages. In this paper, we study gender bias in multilingual embeddings and how it affects transfer learning for NLP applications. We create a multilingual dataset for bias analysis and propose several ways for quantifying bias in multilingual representations from both the intrinsic and extrinsic perspectives. Experimental results show that the magnitude of bias in the multilingual representations changes differently when we align the embeddings to different target spaces and that the alignment direction can also have an influence on the bias in transfer learning. We further provide recommendations for using the multilingual word representations for downstream tasks.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Computers and Society,Computer Science - Machine Learning},
  file = {/Users/siyu/Zotero/storage/NGEBBEJT/Zhao et al. - 2020 - Gender Bias in Multilingual Embeddings and Cross-L.pdf}
}

@inproceedings{zhou2015a,
  title = {End-to-End Learning of Semantic Role Labeling Using Recurrent Neural Networks},
  booktitle = {Proceedings of the 53rd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} and the 7th {{International Joint Conference}} on {{Natural Language Processing}} ({{Volume}} 1: {{Long Papers}})},
  author = {Zhou, Jie and Xu, Wei},
  date = {2015-07},
  pages = {1127--1137},
  publisher = {{Association for Computational Linguistics}},
  location = {{Beijing, China}},
  doi = {10.3115/v1/P15-1109},
  url = {https://aclanthology.org/P15-1109},
  urldate = {2022-06-07},
  eventtitle = {{{ACL-IJCNLP}} 2015},
  file = {/Users/siyu/Zotero/storage/BW86JL5K/Zhou and Xu - 2015 - End-to-end learning of semantic role labeling usin.pdf}
}

@inproceedings{zhou2019,
  title = {Examining {{Gender Bias}} in {{Languages}} with {{Grammatical Gender}}},
  booktitle = {Proceedings of the 2019 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} and the 9th {{International Joint Conference}} on {{Natural Language Processing}} ({{EMNLP-IJCNLP}})},
  author = {Zhou, Pei and Shi, Weijia and Zhao, Jieyu and Huang, Kuan-Hao and Chen, Muhao and Cotterell, Ryan and Chang, Kai-Wei},
  date = {2019-11},
  pages = {5276--5284},
  publisher = {{Association for Computational Linguistics}},
  location = {{Hong Kong, China}},
  doi = {10.18653/v1/D19-1531},
  url = {https://aclanthology.org/D19-1531},
  urldate = {2022-06-06},
  abstract = {Recent studies have shown that word embeddings exhibit gender bias inherited from the training corpora. However, most studies to date have focused on quantifying and mitigating such bias only in English. These analyses cannot be directly extended to languages that exhibit morphological agreement on gender, such as Spanish and French. In this paper, we propose new metrics for evaluating gender bias in word embeddings of these languages and further demonstrate evidence of gender bias in bilingual embeddings which align these languages with English. Finally, we extend an existing approach to mitigate gender bias in word embedding of these languages under both monolingual and bilingual settings. Experiments on modified Word Embedding Association Test, word similarity, word translation, and word pair translation tasks show that the proposed approaches can effectively reduce the gender bias while preserving the utility of the original embeddings.},
  eventtitle = {{{EMNLP-IJCNLP}} 2019},
  file = {/Users/siyu/Zotero/storage/SLMUEPPA/Zhou et al. - 2019 - Examining Gender Bias in Languages with Grammatica.pdf}
}

